
@article{Fra94,
  title = {Instruments, Nerve Action, and the All-or-None Principle},
  author = {Frank, Robert G.},
  year = {1994},
  journal = {Osiris},
  volume = {9},
  number = {1},
  pages = {208--235},
  doi = {10.1086/368737}
}


@book{Hof22,
  title = {{Theoretische Informatik}},
  author = {Hoffmann, Dirk W.},
  year = {2022},
  edition = {5., aktualisierte Auflage},
  publisher = {{Hanser}},
  address = {{M\"unchen}},
  isbn = {978-3-446-47029-3},
  langid = {german}
}

@article{AA15,
  title = {Neural {{Network Techniques}} for {{Cancer Prediction}}: {{A Survey}}},
  shorttitle = {Neural {{Network Techniques}} for {{Cancer Prediction}}},
  author = {Agrawal, Shikha and Agrawal, Jitendra},
  year = {2015},
  journal = {Procedia Computer Science},
  volume = {60},
  pages = {769--774},
  issn = {18770509},
  doi = {10.1016/j.procs.2015.08.234},
  %urldate = {2023-09-07},
  abstract = {Cancer is a dreadful disease. Millions of people died every year because of this disease. It is very essential for medical practitioners to opt a proper treatment for cancer patients. Therefore cancer cells should be identified correctly. Neural networks are currently a burning research area in medical science, especially in the areas of cardiology, radiology, oncology, urology and etc. In this paper, we are surveying various neural network technologies for classification of cancer. The main aim of this survey in medical diagnostics is to guide researchers to develop most cost effective and user friendly systems, processes and approaches for clinicians.},
  langid = {english},
  file = {C:\Users\thorstensuckow\Zotero\storage\WG5FHWAP\Agrawal und Agrawal - 2015 - Neural Network Techniques for Cancer Prediction A.pdf}
}

@article{AAB+23,
  title = {From {{Pavlov Conditioning}} to {{Hebb Learning}}},
  author = {Agliari, Elena and Aquaro, Miriam and Barra, Adriano and Fachechi, Alberto and Marullo, Chiara},
  year = {2023},
  month = apr,
  journal = {Neural Computation},
  volume = {35},
  number = {5},
  pages = {930--957},
  issn = {0899-7667},
  doi = {10.1162/neco_a_01578},
  abstract = {Hebb's learning traces its origin in Pavlov's classical conditioning; however, while the former has been extensively modeled in the past decades (e.g., by the Hopfield model and countless variations on theme), as for the latter, modeling has remained largely unaddressed so far. Furthermore, a mathematical bridge connecting these two pillars is totally lacking. The main difficulty toward this goal lies in the intrinsically different scales of the information involved: Pavlov's theory is about correlations between concepts that are (dynamically) stored in the synaptic matrix as exemplified by the celebrated experiment starring a dog and a ringing bell; conversely, Hebb's theory is about correlations between pairs of neurons as summarized by the famous statement that neurons that fire together wire together. In this letter, we rely on stochastic process theory to prove that as long as we keep neurons' and synapses' timescales largely split, Pavlov's mechanism spontaneously takes place and ultimately gives rise to synaptic weights that recover the Hebbian kernel.}
}

@book{AB16,
  title = {From {{Neuron}} to {{Cognition}} via {{Computational Neuroscience}}},
  author = {Arbib, Michael A. and Bonaiuto, James J.},
  year = {2016},
  publisher = {{The MIT Press}},
  abstract = {This textbook presents a wide range of subjects in neuroscience from a computational perspective. It offers a comprehensive, integrated introduction to core topics, using computational tools to trace a path from neurons and circuits to behavior and cognition. Moreover, the chapters show how computational neuroscience \textendash{} methods for modeling the causal interactions underlying neural systems \textendash{} complements empirical research in advancing the understanding of brain and behavior. The chapters \textendash{} all by leaders in the field, and carefully integrated by the editors \textendash{} cover such subjects as action and motor control; neuroplasticity, neuromodulation, and reinforcement learning; vision; and language \textendash{} the core of human cognition. The book can be used for advanced undergraduate or graduate level courses. It presents all necessary background in neuroscience beyond basic facts about neurons and synapses and general ideas about the structure and function of the human brain. Students should be familiar with differential equations and probability theory, and be able to pick up the basics of programming in MATLAB and/or Python. Slides, exercises, and other ancillary materials are freely available online, and many of the models described in the chapters are documented in the brain operation database, BODB (which is also described in a book chapter). Contributors Michael A. Arbib, Joseph Ayers, James Bednar, Andrej Bicanski, James J. Bonaiuto, Nicolas Brunel, Jean-Marie Cabelguen, Carmen Canavier, Angelo Cangelosi, Richard P. Cooper, Carlos R. Cortes, Nathaniel Daw, Paul Dean, Peter Ford Dominey, Pierre Enel, Jean-Marc Fellous, Stefano Fusi, Wulfram Gerstner, Frank Grasso, Jacqueline A. Griego, Ziad M. Hafed, Michael E. Hasselmo, Auke Ijspeert, Stephanie Jones, Daniel Kersten, Jeremie Knuesel, Owen Lewis, William W. Lytton, Tomaso Poggio, John Porrill, Tony J. Prescott, John Rinzel, Edmund Rolls, Jonathan Rubin, Nicolas Schweighofer, Mohamed A. Sherif, Malle A. Tagamets, Paul F. M. J. Verschure, Nathan Vierling-Claasen, Xiao-Jing Wang, Christopher Williams, Ransom Winder, Alan L. Yuille},
  isbn = {0-262-03496-4},
  file = {C:\Users\thorstensuckow\Zotero\storage\E9KW92I5\From neuron to cognition via computational neuroscience.pdf}
}



@article{Abr02,
  title = {({{Physio}})Logical Circuits: {{The}} Intellectual Origins of the {{McCulloch-Pitts}} Neural Networks},
  shorttitle = {({{Physio}})Logical Circuits},
  author = {Abraham, Tara H.},
  year = 2002,
  journal = {Journal of the History of the Behavioral Sciences},
  volume = {38},
  number = {1},
  pages = {3--25},
  issn = {0022-5061, 1520-6696},
  doi = {10.1002/jhbs.1094},
  %urldate = {2023-08-08},
  langid = {english}
}

@inproceedings{AGM86,
  title = {Concepts {{In Distributed Systems}}},
  booktitle = {Optical and {{Hybrid Computing}}},
  author = {Anderson, James A. and Golden, Richard M. and Murphy, Gregory L.},
  editor = {Szu, Harold H.},
  year = {1986},
  month = feb,
  pages = {260},
  address = {{Leesburg}},
  doi = {10.1117/12.964018}
}

@article{AHS85,
  title = {A Learning Algorithm for Boltzmann Machines},
  author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  year = {1985},
  journal = {Cognitive Science},
  volume = {9},
  number = {1},
  pages = {147--169},
  issn = {0364-0213},
  doi = {10.1016/S0364-0213(85)80012-4}
}

@article{ALP+13,
  title = {Artificial Neural Networks in Medical Diagnosis},
  author = {Amato, Filippo and L{\'o}pez, Alberto and {Pe{\~n}a-M{\'e}ndez}, Eladia Mar{\'i}a and Va{\v n}hara, Petr and Hampl, Ale{\v s} and Havel, Josef},
  year = {2013},
  month = jul,
  journal = {Journal of Applied Biomedicine},
  volume = {11},
  number = {2},
  pages = {47--58},
  issn = {1214021X, 12140287},
  doi = {10.2478/v10136-012-0031-x},
  %urldate = {2023-09-07},
  langid = {english},
}

@book{RHND16,
  doi = {10.1055/b-003-129341},
  year = {2016},
  publisher = {Georg Thieme Verlag},
  editor = {Joachim Rassow and Karin Hauser and Roland Netzker and Rainer Deutzmann},
  title = {Duale Reihe Biochemie}
}

@book{AR88,
  title = {Neurocomputing: {{Foundations}} of {{Research}}},
  editor = {Anderson, James A. and Rosenfeld, Edward},
  year = {1988},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  isbn = {0-262-01097-6}
}

@book{AR98,
  title = {Talking Nets: An oral history of neural networks},
  editor = {Anderson, James A. and Rosenfeld, Edward},
  year = {1998},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  isbn = {0-262-01167-0}
}


@article{Arb00,
  title = {Warren {{McCulloch}}'s {{Search}} for the {{Logic}} of the {{Nervous System}}},
  author = {Arbib, Michael},
  year = {2000},
  month = feb,
  journal = {Perspectives in biology and medicine},
  volume = {43},
  pages = {193--216},
  doi = {10.1353/pbm.2000.0001}
}

@book{Arb03,
  title = {The Handbook of Brain Theory and Neural Networks},
  editor = {Arbib, Michael A.},
  year = {2003},
  edition = {2nd ed},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-01197-6},
  langid = {english},
  lccn = {QP363.3 .H36 2003},
}

@incollection{BB,
  title = {The {{History}} of {{Aerospace Research}} at {{Cornell Aeronautical Laboratory}} and {{Calspan}}},
  booktitle = {44th {{AIAA Aerospace Sciences Meeting}} and {{Exhibit}}},
  author = {Burns, Kevin and Bruckner, Adam},
  doi = {10.2514/6.2006-335}
}


@article{BHU+18,
  title = {Skin {{Cancer Classification Using Convolutional Neural Networks}}: {{Systematic Review}}},
  author = {Brinker, Titus Josef and Hekler, Achim and Utikal, Jochen Sven and Grabe, Niels and Schadendorf, Dirk and Klode, Joachim and Berking, Carola and Steeb, Theresa and Enk, Alexander H and {von Kalle}, Christof},
  year = {2018},
  month = oct,
  journal = {J Med Internet Res},
  volume = {20},
  number = {10},
  eprint = {30333097},
  eprinttype = {pubmed},
  pages = {e11936},
  issn = {1438-8871},
  doi = {10.2196/11936}
}

@incollection{BHW+12,
  title = {Vektorr\"aume Beliebiger {{Dimensionen}}},
  booktitle = {H\"ohere {{Mathematik}} F\"ur {{Ingenieure Band II}}: {{Lineare Algebra}}},
  author = {Burg, Klemens and Haf, Herbert and Wille, Friedrich and Meister, Andreas},
  year = {2012},
  pages = {75--146},
  publisher = {{Vieweg+Teubner Verlag}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-8348-2267-3_2},
  isbn = {978-3-8348-2267-3}
}

@book{SD07,
  doi = {10.1055/b-002-89576},
  year = 2007,
  publisher = {Georg Thieme Verlag},
  editor = {Stefan Silbernagl and Agamemnon Despopoulos},
  title = {Taschenatlas Physiologie}
}

@book{RK18,
  doi = {10.1055/b-005-143299},
  year = {2018},
  publisher = {Georg Thieme Verlag},
  author = {Reinhard Rohkamm and Pawel Kermer},
  title = {Taschenatlas Neurologie}
}

@article{Ber02,
  title = {Untersuchungen Zur {{Thermodynamik}} Der Bioelektrischen {{Str\"ome}}},
  author = {Bernstein, Julius},
  year = {1902},
  month = nov,
  journal = {Archiv f\"ur die gesamte Physiologie des Menschen und der Tiere},
  volume = {92},
  number = {10},
  pages = {521--562},
  issn = {1432-2013},
  doi = {10.1007/BF01790181}
}


@incollection{Ber12,
  title = {Die Membrantheorie},
  booktitle = {Elektrobiologie: {{Die}} Lehre von Den Elektrischen Vorg\"angen Im Organismus Auf Moderner Grundlage Dargestellt},
  author = {Bernstein, Julius},
  year = {1912},
  pages = {87--107},
  publisher = {{Vieweg+Teubner Verlag}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-663-01627-4_5},
  isbn = {978-3-663-01627-4}
}

@article{Ber68,
  title = {Ueber Den Zeitlichen {{Verlauf}} Der Negativen {{Schwankung}} Des {{Nervenstroms}}},
  author = {Bernstein, J.},
  year = {1868},
  month = dec,
  journal = {Archiv f\"ur die gesamte Physiologie des Menschen und der Tiere},
  volume = {1},
  number = {1},
  pages = {173--207},
  issn = {1432-2013},
  doi = {10.1007/BF01640316}
}


@book{BCP18,
  title = {Neurowissenschaften: {{Ein}} Grundlegendes Lehrbuch F\"ur Biologie, Medizin Und Psychologie},
  author = {Bear, Mark F. and Connors, Barry W. and Paradiso, Michael A.},
  editor = {Engel, Andreas K.},
  year = {2018},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-57263-4},
  isbn = {978-3-662-57263-4}
}

@book{KSJ+13,
  title = {Principles of Neural Science, 5th Edition},
  author = {Kandel, E.R. and Schwartz, James H. and Jessell, Thomas M. and Siegelbaum, Steven A. and Hudspeth, A. J.},
  year = {2013},
  series = {{{McGraw-Hill}}'s {{AccessMedicine}}},
  publisher = {{McGraw-Hill Education}},
  isbn = {978-0-07-139011-8},
  lccn = {2012023071}
}


@book{BJ90,
  title = {Neural Computing: An Introduction},
  shorttitle = {Neural Computing},
  author = {Beale, Russell and Jackson, Tom},
  year = {1990},
  series = {A {{Taylor}} \& {{Francis}} Book},
  publisher = {{IOP Publishing}},
  address = {{New York}},
  isbn = {0-85274-262-2},
  langid = {english}
}

@article{BL73,
  title = {Long-Lasting Potentiation of Synaptic Transmission in the Dentate Area of the Anaesthetized Rabbit Following Stimulation of the Perforant Path},
  author = {Bliss, T. V. P. and L{\o}mo, T.},
  year = {1973},
  journal = {The Journal of Physiology},
  volume = {232},
  number = {2},
  pages = {331--356},
  doi = {10.1113/jphysiol.1973.sp010273}
}

@article{BM03,
  title = {The Legacy of {{Donald O}}. {{Hebb}}: More than the {{Hebb Synapse}}},
  author = {Brown, Richard E. and Milner, Peter M.},
  year = {2003},
  month = dec,
  journal = {Nature Reviews Neuroscience},
  volume = {4},
  number = {12},
  pages = {1013--1019},
  issn = {1471-0048},
  doi = {10.1038/nrn1257}
}

@incollection{Bre96,
  title = {Die {{Maxwell-Boltzmann-Verteilung}}},
  booktitle = {Statistische {{Theorie}} Der {{W\"arme}}: {{Gleichgewichtsph\"anomene}}},
  author = {Brenig, Wilhelm},
  year = {1996},
  pages = {55--59},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-61038-7_7},
  isbn = {978-3-642-61038-7}
}



@incollection{Bur,
  title = {The {{History}} of {{Aerospace Research}} at {{Cornell Aeronautical Laboratory}} and {{Calspan}} - 1946 to 1996},
  booktitle = {Space 2004 {{Conference}} and {{Exhibit}}},
  author = {Burns, Kevin},
  doi = {10.2514/6.2004-5884}
}

@article{BY86,
  title = {Spin Glasses: {{Experimental}} Facts, Theoretical Concepts, and Open Questions},
  author = {Binder, K. and Young, A. P.},
  year = {1986},
  month = oct,
  journal = {Rev. Mod. Phys.},
  volume = {58},
  number = {4},
  pages = {801--976},
  publisher = {{American Physical Society}},
  doi = {10.1103/RevModPhys.58.801}
}

@article{Cal20,
  title = {`{{It}} Will Change Everything': {{DeepMind}}'s {{AI}} Makes Gigantic Leap in Solving Protein Structures},
  author = {Callaway, Ewen},
  year = {2020},
  month = dec,
  journal = {Nature},
  volume = {588},
  pages = {203--204},
  doi = {10.1038/d41586-020-03348-4}
}

@inproceedings{CBS+16,
  title = {Doctor {{AI}}: {{Predicting Clinical Events}} via {{Recurrent Neural Networks}}},
  booktitle = {Proceedings of the 1st {{Machine Learning}} for {{Healthcare Conference}}},
  author = {Choi, Edward and Bahadori, Mohammad Taha and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
  editor = {{Doshi-Velez}, Finale and Fackler, Jim and Kale, David and Wallace, Byron and Wiens, Jenna},
  year = {2016},
  month = aug,
  doi = {10.48550/arXiv.1511.05942},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {56},
  pages = {301--318},
  publisher = {{PMLR}},
  address = {{Northeastern University, Boston, MA, USA}}
}

@article{CL78,
  title = {Eye-{{Specific Termination Bands}} in {{Tecta}} of {{Three-Eyed Frogs}}},
  author = {{Constantine-Paton}, Martha and Law, Margaret I.},
  year = {1978},
  journal = {Science},
  volume = {202},
  number = {4368},
  pages = {639--641},
  doi = {10.1126/science.309179}
}

@article{Coo05,
  title = {Donald {{O}}. {{Hebb}}'s Synapse and Learning Rule: A History and Commentary},
  author = {Cooper, Steven J.},
  year = {2005},
  journal = {Neuroscience \& Biobehavioral Reviews},
  volume = {28},
  number = {8},
  pages = {851--874},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2004.09.009}
}

@article{Cow90,
  title = {Discussion: {{McCulloch-Pitts}} and Related Neural Nets from 1943 to 1989},
  author = {Cowan, Jack D.},
  year = {1990},
  month = jan,
  journal = {Bulletin of Mathematical Biology},
  volume = {52},
  number = {1},
  pages = {73--97},
  issn = {1522-9602},
  doi = {10.1007/BF02459569}
}

@incollection{Koc98,
  title = {The Hodgkin-Huxley Model of Action Potential Generation},
  booktitle = {Biophysics of Computation: {{Information}} Processing in Single Neurons},
  author = {Koch, Christof},
  year = {1998},
  month = nov,
  publisher = {{Oxford University Press}},
  doi = {10.1093/oso/9780195139853.003.0012},
  isbn = {978-0-19-510491-2}
}


@article{CS11,
  title = {One {{Cell}} to {{Rule Them All}}, and in the {{Dendrites Bind Them}}},
  author = {Costa, Rui and Sj{\"o}str{\"o}m, P. Jesper},
  year = {2011},
  journal = {Frontiers in Synaptic Neuroscience},
  volume = {3},
  issn = {1663-3563},
  doi = {10.3389/fnsyn.2011.00005}
}

@article{DH20,
  title = {Counterfactual Prediction Is Not Only for Causal Inference},
  author = {Dickerman, Barbra A. and Hern{\'a}n, Miguel A.},
  year = {2020},
  month = jul,
  journal = {European Journal of Epidemiology},
  volume = {35},
  number = {7},
  pages = {615--617},
  issn = {1573-7284},
  doi = {10.1007/s10654-020-00659-8}
}

@incollection{Dor91,
  title = {Konnektionismus \textemdash{} Eine {{Einf\"uhrung}}},
  booktitle = {Konnektionismus: {{Von}} Neuronalen {{Netzwerken}} Zu Einer ,,nat\"urlichen`` {{KI}}},
  author = {Dorffner, Georg},
  year = {1991},
  pages = {15--83},
  publisher = {{Vieweg+Teubner Verlag}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-322-94665-2_2},
  isbn = {978-3-322-94665-2}
}

@article{DOSW08,
  title = {The {{Protein Folding Problem}}},
  author = {Dill, Ken A. and Ozkan, S. Banu and Shell, M. Scott and Weikl, Thomas R.},
  year = {2008},
  journal = {Annual Review of Biophysics},
  volume = {37},
  number = {1},
  pages = {289--316},
  doi = {10.1146/annurev.biophys.37.092707.153558},
  pmid = {18573083}
}

@article{EKN+17,
  title = {Dermatologist-Level Classification of Skin Cancer with Deep Neural Networks},
  author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
  year = {2017},
  month = feb,
  journal = {Nature},
  volume = {542},
  number = {7639},
  pages = {115--118},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature21056},
  %urldate = {2023-09-07},
  langid = {english}
}



@incollection{Ert21a,
  title = {Maschinelles {{Lernen}} Und {{Data Mining}}},
  booktitle = {Grundkurs {{K\"unstliche Intelligenz}}: {{Eine}} Praxisorientierte {{Einf\"uhrung}}},
  author = {Ertel, Wolfgang},
  year = {2021},
  pages = {201--283},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-32075-1_8},
  isbn = {978-3-658-32075-1}
}

@incollection{Ert21b,
  title = {Neuronale Netze},
  booktitle = {Grundkurs K\"unstliche Intelligenz: {{Eine}} Praxisorientierte Einf\"uhrung},
  author = {Ertel, Wolfgang},
  year = {2021},
  pages = {285--349},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-32075-1_9},
  isbn = {978-3-658-32075-1}
}

@incollection{Ert21c,
  title = {Lernen Durch Verst\"arkung (Reinforcement Learning)},
  booktitle = {Grundkurs K\"unstliche Intelligenz: {{Eine}} Praxisorientierte Einf\"uhrung},
  author = {Ertel, Wolfgang},
  year = {2021},
  pages = {351--377},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-32075-1_10},
  isbn = {978-3-658-32075-1}
}


@incollection{Eil19,
  title = {Nervenzellen},
  booktitle = {Physiologie Des Menschen: Mit Pathophysiologie},
  author = {Eilers, J.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {57--64},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_5},
  isbn = {978-3-662-56468-4}
}


@incollection{Fak19,
  title = {Grundlagen Der Zellul\"aren {{Erregbarkeit}}},
  booktitle = {Physiologie Des {{Menschen}}: Mit {{Pathophysiologie}}},
  author = {Fakler, B.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {38--54},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_4},
  isbn = {978-3-662-56468-4}
}

@book{Fau94,
  title = {Fundamentals of {{Neural Networks}}: {{Architectures}}, {{Algorithms}}, and {{Applications}}},
  author = {Fausett, Laurene},
  year = {1994},
  publisher = {{Prentice-Hall, Inc.}},
  address = {{USA}},
  isbn = {0-13-334186-0}
}

@article{FC54,
  title = {Simulation of Self-Organizing Systems by Digital Computer},
  author = {Farley, B. and Clark, W.},
  year = {1954},
  journal = {Transactions of the IRE Professional Group on Information Theory},
  volume = {4},
  number = {4},
  pages = {76--84},
  doi = {10.1109/TIT.1954.1057468}
}

@incollection{FE19,
  title = {Ruhemembranpotenzial Und {{Aktionspotenzial}}},
  booktitle = {Physiologie Des {{Menschen}}: Mit {{Pathophysiologie}}},
  author = {Fakler, B. and Eilers, J.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {65--71},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_6},
  isbn = {978-3-662-56468-4}
}

@incollection{Rau88,
  title = {Aussagenlogik},
  booktitle = {Einf\"uhrung in Die Mathematische Logik: {{Ein}} Lehrbuch},
  author = {Rautenberg, Wolfgang},
  year = {2008},
  pages = {1--32},
  publisher = {{Vieweg+Teubner}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-8348-9530-1_1},
  isbn = {978-3-8348-9530-1}
}


@incollection{Fis19,
  title = {Lineare {{Geometrie}} Im N-Dimensionalen Reellen {{Raum}}},
  booktitle = {Lernbuch {{Lineare Algebra}} Und {{Analytische Geometrie}}: {{Das Wichtigste}} Ausf\"uhrlich F\"ur Das {{Lehramts-}} Und {{Bachelorstudium}}},
  author = {Fischer, Gerd},
  year = {2019},
  pages = {1--82},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-27343-9_1},
  isbn = {978-3-658-27343-9}
}

@incollection{Jeb11,
  title = {Einf\"uhrung},
  booktitle = {Glastechnische Fabrikationsfehler: ``{{Pathologische}}'' Ausnahmezust\"ande Des Werkstoffes Glas Und Ihre Behebung; Eine Br\"ucke Zwischen Wissenschaft, Technologie Und Praxis},
  author = {{Von Jebsen-Marwedel}, H.},
  editor = {{Jebsen-Marwedel}, Hans and Br{\"u}ckner, Rolf},
  year = {2011},
  pages = {3--15},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-16433-0_1},
  isbn = {978-3-642-16433-0}
}


@article{FJOA19,
  title = {Effect of Annealing on the Mechanical Characteristics of Steel Welded Joint},
  author = {Fayomi, O.S.I. and Joshua, T.O. and Olatuja, F.H. and Agboola, O.},
  year = {2019},
  journal = {Procedia Manufacturing},
  volume = {35},
  pages = {1387--1394},
  issn = {23519789},
  doi = {10.1016/j.promfg.2019.09.008},
  %urldate = {2023-09-05},
  langid = {english}
}

@article{FMI83,
  title = {Neocognitron: {{A}} Neural Network Model for a Mechanism of Visual Pattern Recognition},
  author = {Fukushima, Kunihiko and Miyake, Sei and Ito, Takayuki},
  year = {1983},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {SMC-13},
  number = {5},
  pages = {826--834},
  doi = {10.1109/TSMC.1983.6313076}
}

@article{FMMS01,
  title = {Influence of Annealing on the Microstructural, Tensile and Fracture Properties of Polypropylene Films},
  author = {{Ferrer-Balas}, D. and Maspoch, M. Ll and Martinez, A. B. and Santana, O. O.},
  year = {2001},
  journal = {Polymer},
  volume = {42},
  number = {4},
  pages = {1697--1705},
  issn = {0032-3861},
  doi = {10.1016/S0032-3861(00)00487-0},
  abstract = {The influence of annealing temperature on the fracture properties of iPP films (one homopolymer and two propylene\textendash ethylene block copolymers) is presented. The fracture behaviour is studied by means of the Essential Work of Fracture (EWF) procedure, and is complemented by the study of the effect of thermal treatment on tensile properties and microstructure, using differential scanning calorimetry (DSC) and wide-angle X-ray scattering (WAXS). It is shown that the initial metastable phase of quenched iPP films, widely known as smectic, transforms gradually into the monoclinic form as the annealing temperature is increased, resulting in an important improvement of the tensile properties, whereas the fracture parameters have different evolutions depending on the ethylene content. The reasons for a decrease in the essential work term and an increase in the plastic term as the crystal perfection grows are discussed on the basis of the microstructural changes of the crystalline phase and the smectic\textendash monoclinic strain-induced phase transformation.},
  keywords = {Annealing,Essential work of fracture,Polypropylene}
}

@incollection{Fro19,
  title = {Transport in {{Membranen}} Und {{Epithelien}}},
  booktitle = {Physiologie Des {{Menschen}}: Mit {{Pathophysiologie}}},
  author = {Fromm, M.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {22--37},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_3},
  abstract = {Zellmembranen und Epithelien halten durch ihre Barrierefunktion und den Transport von Soluten und Wasser ein konstantes inneres Milieu aufrecht. Transport durch Epithelien erfolgt transzellul\"ar durch die Zellmembranen und parazellul\"ar durch die tight junction. Transport durch Zellmembranen wird durch Kan\"ale, Carrier und Pumpen (Transport-ATPasen) vermittelt. Die tight junction besteht aus abdichtenden und kanalbildenden Proteinen. Epithelien werden als ,,leck`` bezeichnet, wenn die tight junction permeabler f\"ur Ionen ist als die apikale Zellmembran (z.B. proximales Nephron, D\"unndarm), w\"ahrend es bei ,,dichten`` Epithelien umgekehrt ist (z.B. distales Nephron, Dickdarm). Man unterscheidet passiven und aktiven Transport. Passiver Transport wird durch Gradienten getrieben (Filtration durch hydrostatischen Druck; Diffusion durch Konzentrations- und Spannungsgradienten) und verl\"auft stets ,,bergab``. Aktiver Transport kann gegen diese Gradienten ,,bergauf`` erfolgen. Prim\"ar aktiver Transport erfolgt durch Pumpen. Sekund\"ar aktiver Transport wird durch Ionengradienten angetrieben, die durch Pumpen aufgebaut wurden. Hierbei wird durch Ausnutzung eines ,,bergab`` f\"uhrenden Ionengradienten eine andere Substanz ,,bergauf`` transportiert. Terti\"ar aktiver Transport wird durch sekund\"ar aktiven Transport angetrieben.},
  isbn = {978-3-662-56468-4}
}



@incollection{FS90,
  title = {Einf\"uhrung},
  booktitle = {Expertensysteme},
  author = {Friedrich, Gerhard and Stumptner, Markus},
  editor = {Gottlob, Georg and Fr{\"u}hwirth, Thomas and Horn, Werner},
  year = {1990},
  pages = {1--19},
  publisher = {{Springer Vienna}},
  address = {{Vienna}},
  doi = {10.1007/978-3-7091-9094-4_1},
  abstract = {Die Konstruktion von Expertensystemen hat sich zu einem Hauptanwendungsgebiet der Artificial Intelligence (AI) entwickelt. Ausgehend von den Zielen der AI werden im folgenden die Methoden dieser Wissenschaft skizziert. Nach einem kurzen \"Uberblick \"uber die Anwendungsgebiete werden Einsatzgebiete und grundlegende Konstruktionsprinzipien von Expertensystemen vorgestellt.},
  isbn = {978-3-7091-9094-4}
}

@article{Fuk75,
  title = {Cognitron: {{A}} Self-Organizing Multilayered Neural Network},
  author = {Fukushima, Kunihiko},
  year = {1975},
  month = sep,
  journal = {Biological Cybernetics},
  volume = {20},
  number = {3},
  pages = {121--136},
  issn = {1432-0770},
  doi = {10.1007/BF00342633},
}

@article{Fuk80,
  title = {Neocognitron: {{A}} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  author = {Fukushima, Kunihiko},
  year = {1980},
  month = apr,
  journal = {Biological Cybernetics},
  volume = {36},
  number = {4},
  pages = {193--202},
  issn = {1432-0770},
  doi = {10.1007/BF00344251},
}

@article{Gar19,
  title = {Artificial {{Intelligence}} and {{Japan}}'s {{Fifth Generation}}: {{The Information Society}}, {{Neoliberalism}}, and {{Alternative Modernities}}},
  author = {Garvey, Colin},
  year = {2019},
  month = nov,
  journal = {Pacific Historical Review},
  volume = {88},
  number = {4},
  pages = {619--658},
  issn = {0030-8684},
  doi = {10.1525/phr.2019.88.4.619},
  abstract = {In 1982, Japan launched its Fifth Generation Computer Systems project (FGCS), designed to develop intelligent software that would run on novel computer hardware. As the first national, large-scale artificial intelligence (AI) research and development (R\&amp;D) project to be free from military influence and corporate profit motives, the FGCS was open, international, and oriented around public goods. Although the FGCS did not plan any commercialized technologies, many American computer experts portrayed it as an economic threat to U.S. dominance in computing and the global economy\textemdash and policymakers around the developed world believed them and funded AI projects of their own. Later, however, the FGCS was remembered as a failure. Why? This article recasts the FGCS as an interstice in the shift from a state-funded regime of American science organization to the neoliberal privatized regime of R\&amp;D now ascendant around the world. By exploring how notions of economic competitiveness and national security shaped R\&amp;D, this article reveals AI to be a product of contingent choices by multiple actors\textemdash nation-states, government bureaucracies, corporations, and individuals\textemdash rather than the outcome of deterministic technological forces.}
}

@book{GBC18,
  title = {{Deep Learning. Das umfassende Handbuch}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2018},
  month = oct,
  series = {{mitp Professional}},
  edition = {2018},
  publisher = {{MITP}},
  address = {{Frechen, Germany}},
  langid = {ngerman},
  isbn={978-3-95845-700-3}
}


@article{HVKJ82,
  title = {Paradoxical Heat Sensations during Moderate Cooling of the Skin},
  author = {H{\"a}m{\"a}l{\"a}inen, H. and Vartiainen, M. and Karvanen, L. and J{\"a}rvilehto, T.},
  year = {1982},
  journal = {Brain Research},
  volume = {251},
  number = {1},
  pages = {77--81},
  issn = {0006-8993},
  doi = {10.1016/0006-8993(82)91275-6},
  abstract = {Paradoxical heat sensations during cooling of the skin were examined in two experiments. In Expt. I the number of occurrences of sensation was studied in 19 naive test subjects (Ss) when cooling from thermal indifference both without and with preceding heating. Without preceding heating 13 Ss reported sensations of paradoxical heat (9.8\% of all stimulations). Preheating markedly facilitated the occurrence of the sensations (35\% of all stimulations). In Expt. II the effects of cooling velocity (velocities 0.4, 0.7 and 2.0 \textdegree C/s) and the type of skin area stimulated (hairy or glabrous skin of the hand) on the thresholds of paradoxical sensations were studied in 4 Ss without and with preheating. Cooling velocity, type of skin area and preheatting had significant effects on the sensation thresholds, the thresholds being the higher (i.e. the sensation appearing at lower stimulation temperatures) the higher the cooling velocity, if the stimuli were applied to the glabrous skin, or if no preheating was used. The results confirm the existence of paradoxical heat sensations during cooling of the skin and suggest that thesensation is mediated by polymodal units supplied by C-fibers.},
  keywords = {man,paradoxical sensation,thermoreception}
}

@article{Heb,
  title = {The {{Hebb Legacy}}},
  author = {Hebb, Donald Olding},
  doi = {10.1037/h0087295},
  langid = {english}
}

@incollection{Heb1988,
  title = {The {{Organization}} of {{Behavior}}},
  booktitle = {Neurocomputing: {{Foundations}} of {{Research}}},
  author = {Hebb, Donald O.},
  year = {1988},
  pages = {43--54},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  isbn = {0-262-01097-6}
}


@book{Bis06,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, C. M.},
  year = {2006},
  publisher = {{Springer}},
  address = {{New York}}
}

@book{Heb49,
  title = {The Organization of Behavior},
  author = {Hebb, D. O.},
  year = {1949},
  publisher = {{Wiley}},
  address = {{New York}}
}

@incollection{Heb88,
  title = {The {{Organization}} of {{Behavior}}},
  booktitle = {Neurocomputing: {{Foundations}} of {{Research}}},
  author = {Hebb, Donald O.},
  year = {1988},
  pages = {43--54},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  isbn = {0-262-01097-6}
}

@incollection{Heb88a,
  title = {The {{Organization}} of {{Behavior}}},
  booktitle = {Neurocomputing: {{Foundations}} of {{Research}}},
  author = {Hebb, Donald O.},
  year = {1988},
  pages = {43--54},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  isbn = {0-262-01097-6}
}

@article{HG03,
  title = {{Anwendungsbeispiele neuronaler Netze in verschiedenen Bereichen der Medizin}},
  author = {Hitzl, W. and Grabner, G.},
  year = {2003},
  month = jun,
  journal = {Spektrum der Augenheilkunde},
  volume = {17},
  number = {3},
  pages = {103--106},
  issn = {0930-4282, 1613-7523},
  doi = {10.1007/BF03163128},
  %urldate = {2023-09-07},
  langid = {ngerman},
}

@incollection{HI97,
  title = {Introduction (Aus: {{Weakly}} Connected Neural Networks)},
  booktitle = {Weakly {{Connected Neural Networks}}},
  author = {Hoppensteadt, Frank C. and Izhikevich, Eugene M.},
  year = {1997},
  pages = {3--24},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4612-1828-9_1},
  abstract = {In this chapter we give definitions and explanations of basic neurophysio\-logical terminology that we use in the book. We do not intend to provide a comprehensive background on various topics.},
  isbn = {978-1-4612-1828-9}
}


@article{HLW16,
  title = {Densely {{Connected Convolutional Networks}}},
  author = {Huang, Gao and Liu, Zhuang and Weinberger, Kilian Q.},
  year = {2016},
  journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {2261--2269}
}

@article{Hop82,
  title = {Neural {{Networks}} and {{Physical Systems}} with {{Emergent Collective Computational Abilities}}},
  author = {Hopfield, John},
  year = {1982},
  month = may,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {79},
  pages = {2554--8},
  doi = {10.1073/pnas.79.8.2554}
}

@incollection{Hor90,
  title = {Anwendungen von {{Expertensystemen}}},
  booktitle = {Expertensysteme},
  author = {Horn, Werner},
  editor = {Gottlob, Georg and Fr{\"u}hwirth, Thomas and Horn, Werner},
  year = {1990},
  pages = {61--72},
  publisher = {{Springer Vienna}},
  address = {{Vienna}},
  doi = {10.1007/978-3-7091-9094-4_3},
  isbn = {978-3-7091-9094-4}
}

@incollection{HS19b,
  title = {Neurotransmitter Und Ihre {{Rezeptoren}}},
  booktitle = {Physiologie Des {{Menschen}}: Mit {{Pathophysiologie}}},
  author = {Hallermann, S. and Schmidt, R. F.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {105--114},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_10},
  abstract = {Die chemische \"Ubertragung an Synapsen beginnt mit der Freisetzung unterschiedlicher \"Ubertr\"agerstoffe, die als Transmitter bezeichnet werden. Klassische Transmitter sind Acetylcholin, die Aminos\"aure Glutamat und die Monoamine Noradrenalin und Gamma-Aminobutters\"aure (GABA). Damit es nach Transmitterfreisetzung nicht zur dauerhaften synaptischen \"Ubertragung kommt, muss der freigesetzte Transmitter wieder aus dem synaptischen Spalt entfernt werden. Dies geschieht, je nach Transmitter, durch aktive und passive Prozesse. So wird Acetylcholin durch die Cholinesterase gespalten, w\"ahrend im ZNS Glutamat aus dem synaptischen Spalt diffundiert und von Gliazellen aufgenommen wird. F\"ur die Wirkung des Transmitters sind die Typen postsynaptischer Rezeptoren entscheidend. So wirkt Acetylcholin erregend an der motorischen Endplatte, aber hemmend an den Schrittmacherzellen des Herzens. Die synaptische \"Ubertragung kann durch Molek\"ule moduliert werden, die die Synapse verst\"arken (Agonisten) oder abschw\"achen (Antagonisten).},
  isbn = {978-3-662-56468-4}
}

@incollection{HS19a,
  title = {Arbeitsweise von {{Synapsen}}},
  booktitle = {Physiologie Des {{Menschen}}: Mit {{Pathophysiologie}}},
  author = {Hallermann, S. and Schmidt, R. F.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {95--104},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_9},
  abstract = {Nervenzellen k\"onnen \"uber chemische oder elektrische Synapsen kommunizieren. Bei der chemischen Synapse wird ein \"Ubertr\"agerstoff (Transmitter) ausgesch\"uttet, der die nachgeschaltete Zelle beeinflusst. Bei der elektrischen Synapse flie\ss en Ionen durch kleine Poren in der Membran direkt von einer zur anderen Zelle. Im ZNS des Menschen spielen die elektrischen Synapsen eine untergeordnete Rolle. An chemischen Synapsen werden Transmitter in Bl\"aschen aus Doppellipidmembranen (synaptischen Vesikeln) angereichert. Durch die Fusion der Vesikel mit der pr\"asynaptischen Plasmamembran (Exozytose) werden dieTransmitter in den synaptischen Spalt freigesetzt. Die Transmitter diffundieren durch den synaptischen Spalt und binden an postsynaptische Rezeptoren, deren Aktivierung Ionenstr\"ome hervorrufen. Ob die postsynaptische Zelle erregt oder gehemmt wird, h\"angt von der Ionenleitf\"ahigkeit der Rezeptoren ab. Nervenzellen k\"onnen synaptische Signale von nur einer bis hin zu Hundertausenden anderen Nervenzellen erhalten. Hierbei kommt es zu einer r\"aumlichen und zeitlichen Summation der erregenden und hemmenden postsynaptischen Str\"ome.},
  isbn = {978-3-662-56468-4}
}

@article{Gle09,
  title = {{Nobelpreis f\"ur Physiologie und Medizin 1963}},
  author = {Glees, P.},
  year = {2009},
  month = apr,
  journal = {DMW - Deutsche Medizinische Wochenschrift},
  volume = {88},
  number = {52},
  pages = {2523--2526},
  issn = {0012-0472},
  doi = {10.1055/s-0028-1112385},
  langid = {ngerman}
}


@incollection{HS19c,
  title = {Synaptische {{Plastizit\"at}}},
  booktitle = {Physiologie Des {{Menschen}}: Mit {{Pathophysiologie}}},
  author = {Hallermann, S. and Schmidt, R. F.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {115--120},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_11},
  abstract = {Im Rahmen von Adaptation, Lernen und Entwicklung werden Synapsen moduliert. Neben der Neubildung und Elimination von Synapsen kann sich die St\"arke der synaptischen \"Ubertragung auf unterschiedlichen Zeitskalen ver\"andern (Millisekunden \textendash{} Tage), was als synaptische Plastizit\"at bezeichnet wird. Bei einer Verst\"arkung der synaptischen \"Ubertragung spricht man von synaptischer Potenzierung und bei einer Abschw\"achung von synaptischer Depression. Dauert die Ver\"anderung der \"Ubertragungsst\"arke weniger als etwa eine Minute spricht man von Kurzzeitplastizit\"at, andernfalls von Langzeitplastizit\"at. Eine Vielzahl pr\"a- und postsynaptischer Mechanismen ist an der Entstehung verschiedener Formen der synaptischen Plastizit\"at beteiligt, wobei die intrazellul\"are Ca2+-Konzentration meist eine zentrale Rolle spielt.},
  isbn = {978-3-662-56468-4}
}

@inproceedings{HS83,
  title = {Optimal Perceptual Inference},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Hinton, Geoffrey and Sejnowski, Terrence},
  year = {1983},
  month = jan,
  pages = {448--453}
}

@article{HW62,
  title = {Receptive Fields, Binocular Interaction and Functional Architecture in the Cat's Visual Cortex},
  author = {Hubel, D. H. and Wiesel, T. N.},
  year = {1962},
  month = jan,
  journal = {The Journal of Physiology},
  volume = {160},
  number = {1},
  pages = {106--154},
  issn = {00223751},
  doi = {10.1113/jphysiol.1962.sp006837},
  %urldate = {2023-09-05},
  langid = {english}
}

@article{HW62a,
  title = {Receptive Fields, Binocular Interaction and Functional Architecture in the Cat's Visual Cortex},
  author = {Hubel, D. H. and Wiesel, T. N.},
  year = {1962},
  month = jan,
  journal = {The Journal of Physiology},
  volume = {160},
  number = {1},
  pages = {106--154},
  issn = {00223751},
  doi = {10.1113/jphysiol.1962.sp006837},
  %urldate = {2023-09-05},
  langid = {english}
}

@incollection{HWN22,
  title = {Neuronale {{Netze}} Zur {{Effizienzsteigerung}} Der {{Texterkennung}} in Der {{Rezeptabrechnung}}},
  booktitle = {K\"unstliche {{Intelligenz}} Im {{Gesundheitswesen}}: {{Entwicklungen}}, {{Beispiele}} Und {{Perspektiven}}},
  author = {H{\"o}fer, Tobias and Weish{\"a}upl, Frederik and Nischwitz, Alfred},
  editor = {Pfannstiel, Mario A.},
  year = {2022},
  pages = {697--714},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-33597-7_33},
  abstract = {Digitale Bilder sind einer Vielzahl von St\"orungen unterworfen, die eine erfolgreiche Texterkennung erschweren. Der digitale Zwilling enth\"alt unbeabsichtigte Unterschiede zu der realen Bildquelle, die w\"ahrend der Erfassung, Verarbeitung, Komprimierung, Speicherung oder \"Ubertragung entstehen k\"onnen. Als Beispiele f\"ur relevante St\"orfaktoren lassen sich unterbrochene und d\"unne Zeichen, St\"orpixel und Text\"uberlagerungen anf\"uhren. Diese St\"orfaktoren erschweren die automatisierte Erfassung relevanter Daten und machen diese im schlimmsten Fall unbrauchbar. F\"ur die Apothekenrechenzentren bedeutet das einen zus\"atzlichen manuellen Aufwand und damit verbundene Kosten. Dieser Beitrag beschreibt die Entwicklung und Produktivnahme eines neuronalen Netzes bei der NOVENTI, das erfolgreich die St\"orfaktoren des digitalisierten Rezeptbilds reduziert und dadurch eine Effizienzsteigerung der Texterkennung bewirkt.},
  isbn = {978-3-658-33597-7}
}

@article{HH52,
  title = {A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve},
  author = {Hodgkin, A. L. and Huxley, A. F.},
  year = {1952},
  journal = {The Journal of Physiology},
  volume = {117},
  number = {4},
  pages = {500--544},
  doi = {10.1113/jphysiol.1952.sp004764}
}



@book{AHH+98,
  title = {The Extracellular Matrix. FactsBook},
  author = {Ayad, S. and Boot-Handford, R. and Humphries, M. J. and Kadler, K. E. and Shuttleworth, C. A.},
  edition = {2},
  year = {1998},
  isbn = {0-12-068911-1},
  langid = {english},
  publisher = {{London: Academic Press}}
}


@article{Arb19,
  title = {Warren {{McCulloch}}'s {{Search}} for the {{Logic}} of the {{Nervous System}}},
  author = {Arbib, Michael A},
  year = {2000},
  journal = {Perspectives in Biology and Medicine},
  volume = {43},
  number = {2},
  pages = {193--216},
  issn = {1529-8795},
  doi = {10.1353/pbm.2000.0001},
  %urldate = {2023-09-18},
  langid = {english}
}


@misc{IRK+19,
  title = {{{CheXpert}}: {{A Large Chest Radiograph Dataset}} with {{Uncertainty Labels}} and {{Expert Comparison}}},
  shorttitle = {{{CheXpert}}},
  author = {Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and Yu, Yifan and {Ciurea-Ilcus}, Silviana and Chute, Chris and Marklund, Henrik and Haghgoo, Behzad and Ball, Robyn and Shpanskaya, Katie and Seekins, Jayne and Mong, David A. and Halabi, Safwan S. and Sandberg, Jesse K. and Jones, Ricky and Larson, David B. and Langlotz, Curtis P. and Patel, Bhavik N. and Lungren, Matthew P. and Ng, Andrew Y.},
  year = {2019},
  month = jan,
  number = {arXiv:1901.07031},
  eprint = {1901.07031},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  %urldate = {2023-09-09},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing}
}

@article{CC39,
  title = {Electric Impedance of the Squid Giant Axon during Activity},
  author = {Cole, Kenneth S. and Curtis, Howard J.},
  year = {1939},
  month = may,
  journal = {Journal of General Physiology},
  volume = {22},
  number = {5},
  pages = {649--670},
  issn = {0022-1295},
  doi = {10.1085/jgp.22.5.649}
}


@article{JEP+21,
  title = {Highly Accurate Protein Structure Prediction with {{AlphaFold}}},
  author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v Z}{\'i}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and {Romera-Paredes}, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
  year = {2021},
  month = aug,
  journal = {Nature},
  volume = {596},
  number = {7873},
  pages = {583--589},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03819-2},
  abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1\textendash 4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence\textemdash the structure prediction component of the `protein folding problem'8\textemdash has been an important open research problem for more than 50~years9. Despite recent progress10\textendash 14, existing methods fall far~short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
}

@book{Jon07,
  title = {Artificial {{Intelligence}}: {{A Systems Approach}}},
  author = {Jones, M. Tim},
  year = {2007},
  edition = {1},
  publisher = {{Infinity Science Press}},
  abstract = {This book offers students and AI programmers a new perspective on the study of artificial intelligence concepts. The essential topics and theory of AI are presented, but it also includes practical information on data input \& reduction as well as data output (i.e., algorithm usage). Because traditional AI concepts such as pattern recognition, numerical optimization and data mining are now simply types of algorithms, a different approach is needed. This sensor / algorithm / effecter approach grounds the algorithms with an environment, helps students and AI practitioners to better understand them, and subsequently, how to apply them. The book has numerous up to date applications in game programming, intelligent agents, neural networks, artificial immune systems, and more. A CD-ROM with simulations, code, and figures accompanies the book. *Features *Covers not only AI theory, but modern applications e.g., game programming, machine learning, swarming, artificial immune systems, genetic algorithms, pattern recognition, numerical optimization, data mining, and more *Discusses the various computer languages of AI from LISP to JAVA and Python *Includes a CD-ROM with 100MB of simulations, code, and fi gures *Table of Contents 1. Introduction. 2. Search. 3. Games. 4. Logic. 5. Planning. 6. Knowledge Representation. 7. Machine Learning. 8. Probabilistic Reasoning. 9. Stochastic Search. 10. Neural Networks. 11. Intelligent Agents. 12. Hybrid Models. 13. Languages of AI.},
  isbn = {0-9778582-3-5}
}

@incollection{Flo19,
  title = {Lernen},
  booktitle = {Physiologie Des Menschen: Mit Pathophysiologie},
  author = {Flor, H.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {827--838},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_66},
  abstract = {Lernen bezeichnet die F\"ahigkeit des Organismus sich durch Erfahrung an die Umwelt anzupassen. Neben nichtassoziativen Lernprozessen spielen das assoziative Lernen und kognitive Prozesse eine wichtige Rolle. Lernen interagiert mit Reifungsprozessen und f\"uhrt zu lebenslanger Plastizit\"at. Neurobiologische Grundlage des Lernens ist die synaptische Plastizit\"at, die bei langanhaltenden Ged\"achtnisprozessen in strukturelle Ver\"anderungen \"ubergeht. Lernprozesse spielen bei psychischen St\"orungen eine wichtige Rolle, modulieren aber auch somatische Erkrankungen und sind besonders wichtig in der Neurorehabilitation.},
  isbn = {978-3-662-56468-4}
}


@incollection{Jon19,
  title = {Aktionspotenzial: {{Fortleitung}} Im {{Axon}}},
  booktitle = {Physiologie Des {{Menschen}}: Mit {{Pathophysiologie}}},
  author = {Jonas, P.},
  editor = {Brandes, Ralf and Lang, Florian and Schmidt, Robert F.},
  year = {2019},
  pages = {72--82},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-56468-4_7},
  abstract = {Neurone empfangen Eingangssignale, konvertieren diese in Aktionspotenziale und generieren schlie\ss lich Ausgangssignale auf ihren Zielzellen. Dabei sind die zu \"uberwindenden r\"aumlichen Distanzen oft gro\ss. Daher ist entscheidend, dass elektrische Signale in Nervenzellen schnell von einem zum anderen Ort geleitet werden k\"onnen. Diese wichtige Aufgabe erf\"ullt das Axon, der ,,Ausgangsfortsatz`` der Nervenzelle. F\"ur die schnelle Leitung des Aktionspotenzials sind sowohl die passiven Eigenschaften des axonalen Kabels als auch die aktiven Eigenschaften der Zellmembran von entscheidender Bedeutung. Die Evolution bedient sich zweier Tricks, um die Leitungsgeschwindigkeit des Aktionspotenzials zu maximieren. Der eine Trick ist die Zunahme des Axondurchmessers. Der andere Trick ist die Ausbildung von Markscheiden. Dies f\"uhrt bei nahezu gleichem Platzbedarf zu einer Zunahme der Leistungsgeschwindigkeit um fast zwei Gr\"o\ss enordnungen. Die Aktionspotenzialleitung an myelinisierten Axonen erfolgt ,,saltatorisch``.},
  isbn = {978-3-662-56468-4}
}

@article{Jon99,
  title = {Golgi, {{Cajal}} and the {{Neuron Doctrine}}},
  author = {Jones, Edward G.},
  year = {1999},
  journal = {Journal of the History of the Neurosciences},
  volume = {8},
  number = {2},
  pages = {170--178},
  publisher = {{Routledge}},
  doi = {10.1076/jhin.8.2.170.1838},
  pmid = {11624298}
}

@misc{KB17,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  number = {arXiv:1412.6980},
  eprint = {1412.6980},
  primaryclass = {cs},
  publisher = {{arXiv}},
  %%urldate = {2023-09-06},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
}

@article{KG14,
  title = {Hebbian Learning and Predictive Mirror Neurons for Actions, Sensations and Emotions},
  author = {Keysers, Christian and Gazzola, Valeria},
  year = {2014},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {369},
  number = {1644},
  pages = {20130175},
  doi = {10.1098/rstb.2013.0175},
  abstract = {Spike-timing-dependent plasticity is considered the neurophysiological basis of Hebbian learning and has been shown to be sensitive to both contingency and contiguity between pre- and postsynaptic activity. Here, we will examine how applying this Hebbian learning rule to a system of interconnected neurons in the presence of direct or indirect re-afference (e.g. seeing/hearing one's own actions) predicts the emergence of mirror neurons with predictive properties. In this framework, we analyse how mirror neurons become a dynamic system that performs active inferences about the actions of others and allows joint actions despite sensorimotor delays. We explore how this system performs a projection of the self onto others, with egocentric biases to contribute to mind-reading. Finally, we argue that Hebbian learning predicts mirror-like neurons for sensations and emotions and review evidence for the presence of such vicarious activations outside the motor system.}
}

@article{Kle99,
  title = {The {{Hebb}} Legacy.},
  author = {Klein, Raymond M.},
  year = {1999},
  journal = {Canadian Journal of Experimental Psychology / Revue canadienne de psychologie exp\'erimentale},
  volume = {53},
  number = {1},
  pages = {1--3},
  publisher = {{Canadian Psychological Association}},
  address = {{Canada}},
  issn = {1878-7290(Electronic),1196-1961(Print)},
  doi = {10.1037/h0087295},
  abstract = {Discusses the influence of Donald Olding Hebb (1904\textendash 1985) on the discipline of psychology. The author notes that Hebb's principled opposition to radical behaviourism and emphasis on understanding what goes on between stimulus and response (perception, learning, thinking) helped clear the way for the cognitive revolution. His view of psychology as a biological science and his neuropsychological cell-assembly proposal rejuvenated interest in physiological psychology. Since his death, Hebb's seminal ideas exert an ever-growing influence on those interested in mind (cognitive science), brain (neuroscience), and how brains implement mind (cognitive neuroscience). Specific events in Hebb's career are outlined, with particular attention to the influence on psychology of his book The Organization of Behavior: A Neuropsychological Theory (1949). (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {*History of Psychology,*Neuropsychology,Theories}
}

@article{Anf73,
  title = {Principles That Govern the Folding of Protein Chains},
  author = {{Christian B. Anfinsen}},
  year = {1973},
  journal = {Science (New York, N.Y.)},
  volume = {181},
  number = {4096},
  pages = {223--230},
  doi = {10.1126/science.181.4096.223}
}


@book{Koh90,
  title = {Neurale {{Netze}}},
  author = {K{\"o}hle, Monika},
  year = {1990},
  publisher = {{Springer Vienna}},
  address = {{Vienna}},
  isbn = {978-3-7091-9093-7},
}

@article{KSEB21,
  title = {Kreislauftherapie Bei {{Sepsis}} \textendash{} Wann, Wie Und Wie Viel?},
  author = {Kochanek, Matthias and {Shimabukuro-Vornhagen}, Alexander and Eichenauer, Dennis A. and B{\"o}ll, Boris},
  year = {2021},
  month = feb,
  journal = {Wiener klinisches Magazin},
  volume = {24},
  number = {1},
  pages = {12--17},
  issn = {1613-7817},
  doi = {10.1007/s00740-020-00376-8},
  abstract = {Das Management der h\"amodynamischen Instabilit\"at im Rahmen einer Sepsis bzw. eines septischen Schocks steht in der Notfallversorgung und auf der Intensivstation ganz im Vordergrund. Kreislaufinstabilit\"at hat einen dramatischen Einfluss auf die Rate an Organkomplikationen und die Mortalit\"at bei Sepsis. Nach der Leitlinie zur Therapie der Sepsis soll ein mittlerer arterieller Druck von 65\,mm\,Hg nicht unterschritten werden. Kristalloide balancierte Fl\"ussigkeit und Katecholamine sind die Eckpfeiler des therapeutischen Managements der septischen Kreislaufinstabilit\"at. In diesem Beitrag sollen die wichtigsten Punkte \textendash{} das Was, Wann und Wieviel \textendash{} der Kreislauftherapie pr\"asentiert und kritisch diskutiert werden.}
}

@inproceedings{KSH12,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  editor = {Pereira, F. and Burges, C. J. and Bottou, L. and Weinberger, K. Q.},
  year = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}}
}

@article{Kub30,
  title = {A {{theoretical application to some neurological problems of the properties of excitation waves which move in closed circuits}}},
  author = {Kubie, Lawrence S.},
  year = {1930},
  month = jul,
  journal = {Brain},
  volume = {53},
  number = {2},
  pages = {166--177},
  issn = {0006-8950},
  doi = {10.1093/brain/53.2.166}
}

@incollection{Kup19,
  title = {Einleitung Und {{Lernziele}}},
  booktitle = {Eine Transdisziplin\"are {{Einf\"uhrung}} in Die {{Welt}} Der {{Kybernetik}}: {{Grundlagen}}, {{Modelle}}, {{Theorien}} Und {{Praxisbeispiele}}},
  author = {K{\"u}ppers, E. W. Udo},
  year = {2019},
  pages = {1--3},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-23725-7_1},
  abstract = {Dieses Lehrbuch \"uber ,,Kybernetische Welten`` k\"onnte auch \"uberschrieben werden mit: ,,Die Macht der negativen R\"uckkopplung``.},
  isbn = {978-3-658-23725-7}
}

@article{Lan09,
  title = {Associative Memory Models: From the Cell-Assembly Theory to Biophysically Detailed Cortex Simulations},
  author = {Lansner, Anders},
  year = {2009},
  journal = {Trends in Neurosciences},
  volume = {32},
  number = {3},
  pages = {178--186},
  issn = {0166-2236},
  doi = {10.1016/j.tins.2008.12.002},
  abstract = {The second half of the past century saw the emergence of a theory of cortical associative memory function originating in Donald Hebb's hypotheses on activity-dependent synaptic plasticity and cell-assembly formation and dynamics. This conceptual framework has today developed into a theory of attractor memory that brings together many experimental observations from different sources and levels of investigation into computational models displaying information-processing capabilities such as efficient associative memory and holistic perception. Here, we outline a development that might eventually lead to a neurobiologically grounded theory of cortical associative memory.}
}

@book{MP88,
  title = {Perceptrons: {{An}} Introduction to Computational Geometry},
  author = {Minsky, Marvin and Papert, Seymour A},
  year = {1988},
  publisher = {{MIT Press}},
  address = {{London, England}},
  langid = {english}
}

@article{Sey06,
  title = {Julius {{Bernstein}} (1839\textendash 1917): Pioneer Neurobiologist and Biophysicist},
  author = {Seyfarth, Ernst-August},
  year = {2006},
  month = jan,
  journal = {Biological Cybernetics},
  volume = {94},
  number = {1},
  pages = {2--8},
  issn = {1432-0770},
  doi = {10.1007/s00422-005-0031-y}
}


@book{Min67,
  title = {Computation: Finite and Infinite Machines},
  author = {Minsky, Marvin},
  year = {1967},
  publisher = {{Prentice Hal}},
  address = {{USA}},
  langid = {english}
}




@Inbook{AHR19,
  author="Auer, Christoph
and Hollenstein, Nora
and Reumann, Matthias",
  editor="Haring, Robin",
  title="K{\"u}nstliche Intelligenz im Gesundheitswesen",
  bookTitle="Gesundheit digital: Perspektiven zur Digitalisierung im Gesundheitswesen",
  year="2019",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="33--46",
  isbn="978-3-662-57611-3",
  doi="10.1007/978-3-662-57611-3_3",
 }

@inproceedings{NP16,
  author = {Nguyen, Hoang and Patrick, Jon},
  title = {Text Mining in Clinical Domain: Dealing with Noise},
  year = {2016},
  isbn = {9781450342322},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2939672.2939720},
  booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages = {549–558},
  numpages = {10},
  keywords = {natural languages processing, clinical, text classification, active learning, named-entity recognition},
  location = {San Francisco, California, USA},
  series = {KDD '16}
}

@article{Sch83,
  title={The discovery of the action potential},
  author={Stephen M. Schuetze},
  journal={Trends in Neurosciences},
  year={1983},
  volume={6},
  doi = {10.1016/0166-2236(83)90078-4},
  pages={164-168}
}

@incollection{Lan22,
  title = {Abrechnung Medizinischer {{Leistungen}} Mit K\"unstlicher {{Intelligenz}}},
  booktitle = {K\"unstliche {{Intelligenz}} Im {{Gesundheitswesen}}: {{Entwicklungen}}, {{Beispiele}} Und {{Perspektiven}}},
  author = {Landgrebe, Jobst},
  editor = {Pfannstiel, Mario A.},
  year = {2022},
  pages = {715--726},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-33597-7_34},
  abstract = {Deutschland verausgabt im Gesundheitssystem hunderte von Milliarden pro Jahr. Die Leistungserbringer m\"ussen diese Leistungen den Leistungstr\"agern und Selbstzahlern gegen\"uber abrechnen, um bezahlt zu werden. Dieser Prozess erfolgt heute manuell durch \"Arzte, durch spezialisierte Berufsgruppen (Medizincontroller) oder wird an Dienstleister vergeben. Dieser Beitrag stellt das Potenzial dar, welches sich aus einer automatisierten Abrechnung sowohl der \"arztlichen Leistungen wie der Unterbringungsleistungen ergeben w\"urde, die zusammen \"uber zwei Drittel der Kosten ausmachen. Das Problem wird geschildert, danach werden verschiedene L\"osungsm\"oglichkeiten und deren Potenziale er\"ortert. Es wird gezeigt, dass die gro\ss e Herausforderung in der korrekten Maschineninterpretation der \"arztlichen Sprache und der Verarbeitung von Daten in schematischer, tabellarischer oder handschriftlicher Form besteht.},
  isbn = {978-3-658-33597-7}
}

@article{CBBH98,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  year = {1998},
  journal = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  doi = {10.1109/5.726791}
}



@article{CBD+89,
  title = {Backpropagation {{Applied}} to {{Handwritten Zip Code Recognition}}},
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  year = {1989},
  month = dec,
  journal = {Neural Computation},
  volume = {1},
  number = {4},
  pages = {541--551},
  issn = {0899-7667},
  doi = {10.1162/neco.1989.1.4.541},
  abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.}
}

@incollection{LBDA22,
  title = {Erkl\"arbare {{KI}} in Der Medizinischen {{Diagnose}} \textendash{} {{Erfolge}} Und {{Herausforderungen}}},
  booktitle = {K\"unstliche {{Intelligenz}} Im {{Gesundheitswesen}}: {{Entwicklungen}}, {{Beispiele}} Und {{Perspektiven}}},
  author = {Lucieri, Adriano and Bajwa, Muhammad Naseer and Dengel, Andreas and Ahmed, Sheraz},
  editor = {Pfannstiel, Mario A.},
  year = {2022},
  pages = {727--754},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-33597-7_35},
  abstract = {Der gro\ss e Erfolg moderner, bildbasierter KI-Methoden und das damit einhergehende Interesse f\"ur die Anwendung von KI in kritischen Entscheidungsprozessen f\"uhrte zu einem Anstieg der Bem\"uhungen, intelligente Systeme transparent und erkl\"arbar zu gestalten. Besonders im medizinischen Kontext, wo computergest\"utzte Entscheidungen direkten Einfluss auf die Behandlung und das Wohlsein von Patienten haben k\"onnen, ist Transparenz f\"ur den sicheren \"Ubergang von Forschung in die Praxis von h\"ochster Wichtigkeit. Dieser Beitrag besch\"aftigt sich mit dem aktuellen Stand moderner Methoden zur Erkl\"arung und Interpretation von Deep-Learning-basierten KI-Algorithmen in Anwendungen der medizinischen Forschung und Diagnose von Krankheiten. Zun\"achst werden erste bemerkenswerte Erfolge im Einsatz erkl\"arbarer KI zur Validierung bekannter und Exploration potenzieller Biomarker sowie Methoden zur nachtr\"aglichen Korrektur von KI-Modellen aufgezeigt. Im Anschluss werden einige verbleibende Herausforderungen, die der Anwendung von KI als klinische Entscheidungshilfe im Weg stehen, kritisch diskutiert und Empfehlungen f\"ur die Ausrichtung zuk\"unftiger Forschung ausgesprochen.},
  isbn = {978-3-658-33597-7}
}

@article{LBH15,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.}
}

@inproceedings{Cun89,
  title = {Generalization and {{Network Design Strategies}}},
  booktitle = {Connectionism in {{Perspective}}},
  author = {LeCun, Y.},
  editor = {Pfeifer, R. and Schreter, Z. and Fogelman, F. and Steels, L.},
  year = {1989},
  publisher = {{Elsevier}},
  address = {{Zurich, Switzerland}}
}

@inproceedings{Mcd80,
  title={RI: an Expert in the Computer Systems Domain},
  author={John P. McDermott},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={1980}
}

@inproceedings{LHL+21,
  title = {G-{{Net}}: A {{Recurrent Network Approach}} to {{G-Computation}} for {{Counterfactual Prediction Under}} a {{Dynamic Treatment Regime}}},
  booktitle = {Proceedings of {{Machine Learning}} for {{Health}}},
  author = {Li, Rui and Hu, Stephanie and Lu, Mingyu and Utsumi, Yuria and Chakraborty, Prithwish and Sow, Daby M. and Madan, Piyush and Li, Jun and Ghalwash, Mohamed and Shahn, Zach and Lehman, Li-wei},
  editor = {Roy, Subhrajit and Pfohl, Stephen and Rocheteau, Emma and Tadesse, Girmaw Abebe and Oala, Luis and Falck, Fabian and Zhou, Yuyin and Shen, Liyue and Zamzmi, Ghada and Mugambi, Purity and Zirikly, Ayah and McDermott, Matthew B. A. and Alsentzer, Emily},
  year = {2021},
  month = dec,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {158},
  pages = {282--299},
  publisher = {{PMLR}},
  abstract = {Counterfactual prediction is a fundamental task in decision-making. This paper introduces G-Net, a sequential deep learning framework for counterfactual prediction under dynamic time-varying treatment strategies in complex longitudinal settings. G-Net is based upon g-computation, a causal inference method for estimating effects of general dynamic treatment strategies. Past g-computation implementations have mostly been built using classical regression models. G-Net instead adopts a recurrent neural network framework to capture complex temporal and nonlinear dependencies in the data. To our knowledge, G-Net is the first g-computation based deep sequential modeling framework that provides estimates of treatment effects under \textbackslash emdynamic and \textbackslash emtime-varying treatment strategies. We evaluate G-Net using simulated longitudinal data from two sources: CVSim, a mechanistic model of the cardiovascular system, and a pharmacokinetic simulation of tumor growth. G-Net outperforms both classical and state-of-the-art counterfactual prediction models in these settings.}
}

@article{Lip87,
  title = {An Introduction to Computing with Neural Nets},
  author = {Lippmann, R.},
  year = {1987},
  journal = {IEEE ASSP Magazine},
  volume = {4},
  number = {2},
  pages = {4--22},
  doi = {10.1109/MASSP.1987.1165576}
}

@article{Liu10,
  title = {The {{Cybernetic Unconscious}}: {{Rethinking Lacan}}, {{Poe}}, and {{French Theory}}},
  author = {Liu, Lydia H.},
  year = {2010},
  journal = {Critical Inquiry},
  volume = {36},
  number = {2},
  pages = {288--320},
  doi = {10.1086/648527}
}

@article{Lon96,
  title = {A {{Systematic Introduction}}},
  author = {London, Hong Kong},
  year = {1996},
  journal = {Neural Networks},
  langid = {english},
}

@article{LS92,
  title = {Selection of {{Intrinsic Horizontal Connections}} in the {{Visual Cortex}} by {{Correlated Neuronal Activity}}},
  author = {L{\"o}wel, Siegrid and Singer, Wolf},
  year = {1992},
  journal = {Science},
  volume = {255},
  number = {5041},
  pages = {209--212},
  doi = {10.1126/science.1372754},
  abstract = {In the visual cortex of the brain, long-ranging tangentially oriented axon collaterals interconnect regularly spaced clusters of cells. These connections develop after birth and attain their specificity by pruning. To test whether there is selective stabilization of connections between those cells that exhibit correlated activity, kittens were raised with artificially induced strabismus (eye deviation) to eliminate the correlation between signals from the two eyes. In area 17, cell clusters were driven almost exclusively from either the right or the left eye and tangential intracortical fibers preferentially connected cell groups activated by the same eye. Thus, circuit selection depends on visual experience, and the selection criterion is the correlation of activity.}
}

@article{LST+16,
  title = {Deep Learning as a Tool for Increased Accuracy and Efficiency of Histopathological Diagnosis},
  author = {Litjens, Geert and S{\'a}nchez, Clara I. and Timofeeva, Nadya and Hermsen, Meyke and Nagtegaal, Iris and Kovacs, Iringo and {Hulsbergen - van de Kaa}, Christina and Bult, Peter and {van Ginneken}, Bram and {van der Laak}, Jeroen},
  year = {2016},
  month = may,
  journal = {Scientific Reports},
  volume = {6},
  number = {1},
  pages = {26286},
  issn = {2045-2322},
  doi = {10.1038/srep26286},
  abstract = {Pathologists face a substantial increase in workload and complexity of histopathologic cancer diagnosis due to the advent of personalized medicine. Therefore, diagnostic protocols have to focus equally on efficiency and accuracy. In this paper we introduce `deep learning' as a technique to improve the objectivity and efficiency of histopathologic slide analysis. Through two examples, prostate cancer identification in biopsy specimens and breast cancer metastasis detection in sentinel lymph nodes, we show the potential of this new methodology to reduce the workload for pathologists, while at the same time increasing objectivity of diagnoses. We found that all slides containing prostate cancer and micro- and macro-metastases of breast cancer could be identified automatically while 30\textendash 40\% of the slides containing benign and normal tissue could be excluded without the use of any additional immunohistochemical markers or human intervention. We conclude that `deep learning' holds great promise to improve the efficacy of prostate cancer diagnosis and breast cancer staging.},
}

@incollection{Mas90,
  title = {{{McCulloch}}, {{Pitts}} and the {{Evolution}} of {{Wiener}}'s {{Neurophysiological Ideas}}},
  booktitle = {Norbert {{Wiener}} 1894\textendash 1964},
  author = {Masani, P. R.},
  year = {1990},
  pages = {218--238},
  publisher = {{Birkh\"auser Basel}},
  address = {{Basel}},
  doi = {10.1007/978-3-0348-9252-0_16},
  abstract = {Wiener first met Dr. Warren McCulloch at the neurophysiological meeting in New York in 1942 at which Dr. Rosenblueth presented their joint work with Bigelow on teleology [43b]. McCulloch was then Professor of Psychiatry in the Medical School of the University of Illinois. In 1917 he had entered Haverford College to honor in mathematics, but in the spring went on active duty with the Naval Reserve for a year, teaching celestial navigation to cadets and learning about submarines. He studied philosophy at Yale and psychology (experimental aesthetics) at Columbia before he entered the Columbia Medical School. He became a serious student of mathematical logic, and investigated the mathematico-logical aspects of schizophrenia and psychopathia while serving at the Rockland Hospital for the Insane. His life's mission is disclosed by his amusing exchange with the Quaker philosopher Rufus Jones at Haverford College in 1917:``Warren'', he said, ``what is thee going to be?'' And I said, ``I don't know.'' ``And what is thee going to do?'' And again I said ``I have no idea; but there is one question I would like to answer: What is a number, that a man may know it, and a man, that he may know a number?'' He smiled and said, ``Friend, thee will be busy as long as thee lives.'' I have been\textbackslash ldots \{M13, p. 2\}.},
  isbn = {978-3-0348-9252-0}
}

@book{Mcc04,
  title = {Machines {{Who Think}}: {{A Personal Inquiry}} into the {{History}} and {{Prospects}} of {{Artificial Intelligence}}},
  author = {McCorduck, Pamela},
  year = {2004},
  publisher = {{AK Peters Ltd}},
  isbn = {1-56881-205-1}
}

@book{McC1965,
  title = {Embodiments of Mind.},
  author = {McCulloch, Warren},
  year = {1965},
  series = {Embodiments of Mind.},
  pages = {xx, 402},
  publisher = {{The MIT Press}},
  address = {{Cambridge,  MA,  US}},
  abstract = {Lectures, poetry, and essays of the author reflecting the meeting of his several fields of study: psychiatry, neurophysiology, methematics, cybernetics, and experimental epistemology. Contents include: What Is a Number, That a Man May Know It, and a Man, That He May Know a Number?; A Logical Calculus of the Ideas Imminent in Nervous Activity; A Heterarchy of Values Determined by the Topology of Nervous Nets; How We Know Universals: The Perception of Auditory and Visual Forms; Modes of Functional Organization of the Cerebral Cortex; Why the Mind Is in the Head; Through the Den of the Metaphysician; Mysterium Iniquitatis of Sinful Man Aspiring into the Place of God; Effects of Strychnine with Special Reference to Spinal Afferent Fibres; Reflex Inhibition by Dorsal Root Interaction; Toward Some Circuitry of Ethical Robots or an Observational Science of the Genesis of Social Evaluation in the Mind-Like Behavior of Artifacts; Agatha Tyche: Of Nervous Nets\textemdash the Lucky Reckoners; Where Is Fancy Bred?; What the Frog's Eye Tells the Frog's Brain; Finality and Form; The Past of a Delusion; Machines That Think and Want; The Natural Fit; A Historical Introduction to the Postulation Foundations of Experimental Epistemology; Physiological Processes Underlying Psychoneuroses; What's in the Brain That Ink May Character? (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{MP43,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S. and Pitts, Walter},
  year = {1943},
  month = dec,
  journal = {The bulletin of mathematical biophysics},
  volume = {5},
  number = {4},
  pages = {115--133},
  issn = {1522-9602},
  doi = {10.1007/BF02478259}
}


@incollection{McC51,
  title = {Why the Mind Is in the Head.},
  booktitle = {Cerebral Mechanisms in Behavior; the {{Hixon Symposium}}.},
  author = {McCulloch, Warren S.},
  year = {1951},
  pages = {42--111},
  publisher = {{Wiley}},
  address = {{Oxford,  England}},
  abstract = {An attempt to explain the neurological basis of "mind". The nervous system is considered to be a logical machine and some of the author's earlier work in this area is discussed. Ideas are treated in terms of information theory. The origin of ideas and memory are discussed in terms of nerve nets and negative feedback. The perserveration of perceived shape or form from one neural level to another is explained in terms of the sequential excitation of neural sheets. The mind is in the head because the brain contains the greatest possible neural connections (arranged in sheets) and the largest number of functional inverse feedbacks. A panel discussion is included between the pages 57-82. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{Luc05,
  title = {On the Gradation of Activity in a Skeletal Muscle-Fibre},
  author = {Lucas, Keith},
  year = {1905},
  journal = {The Journal of Physiology},
  volume = {33},
  number = {2},
  pages = {125--137},
  doi = {10.1113/jphysiol.1905.sp001115}
}

@book{Mcc16,
  title = {Embodiments of Mind},
  author = {McCulloch, Warren S},
  year = {2016},
  month = oct,
  publisher = {{MIT Press}},
  address = {{London, England}},
  langid = {english},
  isbn=  {9780262340960},
}

@incollection{SBB+13,
  title = {Chapter 5 - Membrane Potential and Action Potential},
  editor = {Larry R. Squire and Darwin Berg and Floyd E. Bloom and Sascha {du Lac} and Anirvan Ghosh and Nicholas C. Spitzer},
  booktitle = {Fundamental Neuroscience (Fourth Edition)},
  publisher = {Academic Press},
  edition = {Fourth Edition},
  address = {San Diego},
  pages = {93-116},
  year = {2013},
  isbn = {978-0-12-385870-2},
  doi = {10.1016/B978-0-12-385870-2.00005-6},
  author = {David A. McCormick}
}

@article{Mcc55,
  title = {Mysterium Iniquitatis of Sinful Man Aspiring into the Place of {{God}}},
  author = {McCulloch, Warren S.},
  year = {1955},
  journal = {The Scientific monthly},
  volume = {80},
  pages = {35--39}
}

@inproceedings{McC79,
  title = {Machines {{Who Think}}: {{A Personal Inquiry}} into the {{History}} and {{Prospects}} of {{Artificial Intelligence}}},
  author = {McCorduck, Pamela},
  year = {1979}
}

@article{McD,
  title = {{{RI}}: An {{Expert}} in the {{Computer Systems Domain}}'},
  author = {McDermott, John},
  langid = {english},
}

@article{MKM+16,
  title = {{{SMART}} on {{FHIR}}: A Standards-Based, Interoperable Apps Platform for Electronic Health Records},
  author = {Mandel, Joshua C and Kreda, David A and Mandl, Kenneth D and Kohane, Isaac S and Ramoni, Rachel B},
  year = {2016},
  month = feb,
  journal = {Journal of the American Medical Informatics Association},
  volume = {23},
  number = {5},
  pages = {899--908},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocv189}
}

@article{MMA+19,
  title = {Etymology and the Neuron(e)},
  author = {Mehta, Arpan R and Mehta, Puja R and Anderson, Stephen P and MacKinnon, Barbara L H and Compston, Alastair},
  year = {2019},
  month = dec,
  journal = {Brain},
  volume = {143},
  number = {1},
  pages = {374--379},
  issn = {0006-8950},
  doi = {10.1093/brain/awz367}
}

@book{MMM96,
  title = {Brain Processes, Theories, and Models: An International Conference in Honor of {{W}}.{{S}}. {{McCulloch}} 25 Years after His Death},
  shorttitle = {Brain Processes, Theories, and Models},
  editor = {{Moreno-D{\'i}az}, Roberto and Mira, J. and McCulloch, Warren S.},
  year = {1996},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-63170-9},
  langid = {english},
  lccn = {QP376 .B719 1996}
 }

@article{Mur91,
  title = {Multilayer Perceptrons for Classification and Regression},
  author = {Murtagh, Fionn},
  year = {1991},
  journal = {Neurocomputing},
  volume = {2},
  number = {5},
  pages = {183--197},
  issn = {0925-2312},
  doi = {10.1016/0925-2312(91)90023-5},
  abstract = {We review the theory and practice of the multilayer perceptron. We aim at addressing a range of issues which are important from the point of view of applying this approach to practical problems. A number of examples are given, illustrating how the multilayer perceptron compares to alternative, conventional approaches. The application fields of classification and regression are especially considered. Questions of implementation, i.e. of multilayer perceptron architecture, dynamics, and related aspects, are discussed. Recent studies, which are particularly relevant to the areas of discriminant analysis, and function mapping, are cited.},
  keywords = {discriminant analysis,function approximation,Multilayer perceptron,regression,supervised classification}
}

@incollection{Neu56,
  title = {Probabilistic {{Logics}} and the {{Synthesis}} of {{Reliable Organisms From Unreliable Components}}},
  booktitle = {Automata {{Studies}}. ({{AM-34}}), {{Volume}} 34},
  author = {von Neumann, J.},
  editor = {Shannon, C. E. and McCarthy, J.},
  year = {1956},
  pages = {43--98},
  publisher = {{Princeton University Press}},
  address = {{Princeton}},
  doi = {doi:10.1515/9781400882618-003},
  %urldate = {2023-08-07},
  isbn = {978-1-4008-8261-8}
}

@book{NKK94,
  title = {Neuronale {{Netze}} Und {{Fuzzy-Systeme}}},
  author = {Nauck, Detlef and Klawonn, Frank and Kruse, Rudolf},
  year = {1994},
  publisher = {{Vieweg+Teubner Verlag}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-322-85993-8_1},
  abstract = {Neuronale Netze, Expertensysteme und Fuzzy-Systeme erscheinen auf den ersten Blick als v\"ollig verschiedene Gebiete, zwischen denen kaum ein Zusammenhang besteht. In dieser Einleitung erl\"autern wir kurz die Grundkonzepte dieser drei Gebiete, aus denen wir ersehen k\"onnen, da\ss{} eine Kopplung Neuronaler Netze mit Expertensystemen und Fuzzy-Systemen vielversprechende M\"oglichkeiten er\"offnet. Au\ss erdem gehen wir auf den inhaltlichen Aufbau des Buches ein, der sich aus der Intention ergibt, die Verbindungen der konnektionistischen Modelle zu den anderen Gebieten aufzuzeigen.},
  isbn = {978-3-322-85993-8}
}

@article{Nwa,
  title = {Neural {{Networks}}, {{Artificial Intelligence}} and the {{Computational Brain}}},
  author = {Nwadiugwu, Martin C},
  abstract = {In recent years, several studies have provided insight on the functioning of the brain which consists of neurons and form networks via interconnection among them by synapses. Neural networks are formed by interconnected systems of neurons, and are of two types, namely, the Artificial Neural Network (ANNs) and Biological Neural Network (interconnected nerve cells). The ANNs are computationally influenced by human neurons and are used in modelling neural systems. The reasoning foundations of ANNs have been useful in anomaly detection, in areas of medicine such as instant physician, electronic noses, pattern recognition, and modelling biological systems. Advancing research in artificial intelligence using the architecture of the human brain seeks to model systems by studying the brain rather than looking to technology for brain models. This study explores the concept of ANNs as a simulator of the biological neuron, and its area of applications. It also explores why brain-like intelligence is needed and how it differs from computational framework by comparing neural networks to contemporary computers and their modern day implementation.},
  langid = {english}
}

@article{OF05,
  title = {How {{Close Are We}} to {{Understanding V1}}?},
  author = {Olshausen, Bruno A. and Field, David J.},
  year = {2005},
  month = aug,
  journal = {Neural Computation},
  volume = {17},
  number = {8},
  pages = {1665--1699},
  issn = {0899-7667},
  doi = {10.1162/0899766054026639},
  abstract = {A wide variety of papers have reviewed what is known about the function of primary visual cortex. In this review, rather than stating what is known, we attempt to estimate how much is still unknown about V1 function. In particular, we identify five problems with the current view of V1 that stem largely from experimental and theoretical biases, in addition to the contributions of nonlinearities in the cortex that are not well understood. Our purpose is to open the door to new theories, a number of which we describe, along with some proposals for testing them.}
}

@article{Ola96,
  title = {A {{Sociological Study}} of the {{Official History}} of the {{Perceptrons Controversy}}},
  author = {Olazaran, Mikel},
  year = {1996},
  journal = {Social Studies of Science},
  volume = {26},
  number = {3},
  pages = {611--659},
  doi = {10.1177/030631296026003005}
}

@book{PW27,
  title = {Principia mathematica, vol. 1 - 3},
  author = {Whitehead, Alfred North and Russell, Bertrand},
  edition= {2},
  year = {1927},
  publisher = {{Cambridge University Press}},
  isbn = {978-0521067911}
}


@book{OV00,
  title = {Rechneraufbau Und {{Rechnerstrukturen}}},
  author = {Oberschelp, Walter and Vossen, Gottfried},
  edition= {8},
  year = {2000},
  publisher = {{Oldenbourg Wissenschaftsverlag}},
  isbn = {3-486-25340-9}
}

@article{Per88,
  title = {Logical Neurons: The Enigmatic Legacy of {{Warren McCulloch}}},
  author = {Perkel, Donald H.},
  year = {1988},
  journal = {Trends in Neurosciences},
  volume = {11},
  number = {1},
  pages = {9--12},
  issn = {0166-2236},
  doi = {10.1016/0166-2236(88)90041-0}
}

@incollection{Pfa22,
  title = {Einleitung ,,{{K\"unstliche Intelligenz}} Im {{Gesundheitswesen}}``},
  booktitle = {K\"unstliche {{Intelligenz}} Im {{Gesundheitswesen}}: {{Entwicklungen}}, {{Beispiele}} Und {{Perspektiven}}},
  author = {Pfannstiel, Mario A.},
  editor = {Pfannstiel, Mario A.},
  year = {2022},
  pages = {1--47},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-33597-7_1},
  abstract = {Der Einsatz von k\"unstlicher Intelligenz im Gesundheitswesen hat in den letzten Jahren stark zugenommen und durchdringt zunehmend alle Lebens- und Arbeitsbereiche. Die Gesundheitsversorgung durchlebt bereits schon heute tiefgreifende Ver\"anderungen durch die DigitalisierungDigitalisierung. K\"unstliche Intelligenz gilt im Gesundheitswesen und in vielen anderen Branchen als Schl\"ussel- und Querschnittstechnologie. Durch sie wird die digitale Transformation in der Patientenversorgung und medizinischen Forschung beschleunigt.},
  isbn = {978-3-658-33597-7}
}

@article{Pic04,
  title = {The {{First Computational Theory}} of {{Mind}} and {{Brain}}: {{A Close Look}} at {{Mcculloch}} and {{Pitts}}'s ``{{Logical Calculus}} of {{Ideas Immanent}} in {{Nervous Activity}}''},
  author = {Piccinini, Gualtiero},
  year = {2004},
  month = aug,
  journal = {Synthese},
  volume = {141},
  number = {2},
  pages = {175--215},
  issn = {1573-0964},
  doi = {10.1023/B:SYNT.0000043018.52445.3e},
  abstract = {Despite its significance in neuroscience and computation, McCulloch and Pitts's celebrated 1943 paper has received little historical and philosophical attention. In 1943 there already existed a lively community of biophysicists doing mathematical work on neural networks. What was novel in McCulloch and Pitts's paper was their use of logic and computation to understand neural, and thus mental, activity. McCulloch and Pitts's contributions included (i) a formalism whose refinement and generalization led to the notion of finite automata (an important formalism in computability theory), (ii) a technique that inspired the notion of logic design (a fundamental part of modern computer design), (iii) the first use of computation to address the mind\textendash body problem, and (iv) the first modern computational theory of mind and brain.}
}

@article{PM47,
  title = {How We Know Universals the Perception of Auditory and Visual Forms},
  author = {Pitts, Walter and McCulloch, Warren S.},
  year = {1947},
  month = sep,
  journal = {The bulletin of mathematical biophysics},
  volume = {9},
  number = {3},
  pages = {127--147},
  issn = {1522-9602},
  doi = {10.1007/BF02478291},
  abstract = {Two neural mechanisms are described which exhibit recognition of forms. Both are independent of small perturbations at synapses of excitation, threshold, and synchrony, and are referred to partiular appropriate regions of the nervous system, thus suggesting experimental verification. The first mechanism averages an apparition over a group, and in the treatment of this mechanism it is suggested that scansion plays a significant part. The second mechanism reduces an apparition to a standard selected from among its many legitimate presentations. The former mechanism is exemplified by the recognition of chords regardless of pitch and shapes regardless of size. The latter is exemplified here only in the reflexive mechanism translating apparitions to the fovea. Both are extensions to contemporaneous functions of the knowing of universals heretofore treated by the authors only with respect to sequence in time.}
}

@article{PO06,
  title = {Context-Sensitive Autoassociative Memories as Expert Systems in Medical Diagnosis},
  author = {Pomi, Andr{\'e}s and Olivera, Fernando},
  year = {2006},
  month = nov,
  journal = {BMC Medical Informatics and Decision Making},
  volume = {6},
  number = {1},
  pages = {39},
  issn = {1472-6947},
  doi = {10.1186/1472-6947-6-39},
  abstract = {The complexity of our contemporary medical practice has impelled the development of different decision-support aids based on artificial intelligence and neural networks. Distributed associative memories are neural network models that fit perfectly well to the vision of cognition emerging from current neurosciences.}
}


- **[Die17]** Diestel, R. (2017). Graphentheorie. Springer-Verlag, Heidelberg. ISBN: 9783961340040

@book{Die17,
  title = {Graphentheorie},
  author = {Diestel, R.},
  year = {2017},
  publisher = {Springer-Verlag},
  address = {Heidelberg},
  isbn = {9783961340040}
}


@book{Ras16,
  title = {Make {{Your Own Neural Network}}: {{A Gentle Journey Through}} the {{Mathematics}} of {{Neural Networks}}, and {{Making Your Own Using}} the {{Python Computer Language}}},
  author = {Rashid, T.},
  year = {2016},
  publisher = {{CreateSpace Independent Publishing Platform}},
  isbn = {978-1-5308-2660-5}
}



@article{RHW86,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  year = {1986},
  month = oct,
  journal = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  issn = {1476-4687},
  doi = {10.1038/323533a0},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.}
}

@inproceedings{Nov62,
  added-at = {2008-05-16T13:38:37.000+0200},
  address = {New York, NY, USA},
  author = {Novikoff, A. B.},
  booktitle = {Proceedings of the Symposium on the Mathematical Theory of Automata},
  interhash = {e7c4be0dc18ab2ee45f45d22a37be579},
  intrahash = {4c06627268557e99a9f1ea2999099558},
  keywords = {linear-classification},
  pages = {615--622},
  publisher = {Polytechnic Institute of Brooklyn},
  timestamp = {2008-05-16T13:38:38.000+0200},
  title = {On Convergence Proofs on Perceptrons},
  volume = 12,
  year = 1962
}



@incollection{RM87,
  title = {{{PDP Models}} and {{General Issues}} in {{Cognitive Science}}},
  booktitle = {Parallel {{Distributed Processing}}: {{Explorations}} in the {{Microstructure}} of {{Cognition}}: {{Foundations}}},
  author = {Rumelhart, David E. and McClelland, James L.},
  year = {1987},
  pages = {110--146}
}

@book{RN09,
  title = {{K\"unstliche Intelligenz}},
  author = {Russell, Stuart and Norvig, Peter},
  year = {2012},
  month = jun,
  series = {{Pearson Studium - IT}},
  edition = {3},
  publisher = {{Pearson Studium ein Imprint von Pearson Deutschland}},
  address = {{Munich, Germany}},
  langid = {ngerman},
  isbn={978-3-86894-098-5}
}


@article{ROC+18,
  title = {Scalable and Accurate Deep Learning with Electronic Health Records},
  author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M. and Hajaj, Nissan and Hardt, Michaela and Liu, Peter J. and Liu, Xiaobing and Marcus, Jake and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Zhang, Yi and Flores, Gerardo and Duggan, Gavin E. and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L. and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H. and Butte, Atul J. and Howell, Michael D. and Cui, Claire and Corrado, Greg S. and Dean, Jeffrey},
  year = {2018},
  month = may,
  journal = {npj Digital Medicine},
  volume = {1},
  number = {1},
  pages = {18},
  issn = {2398-6352},
  doi = {10.1038/s41746-018-0029-1}
}


@book{Roj93,
  doi = {10.1007/978-3-642-61231-2},
  year = {1993},
  publisher = {Springer Berlin Heidelberg},
  author = {Ra{\'{u}}l Rojas},
  title = {Theorie der neuronalen Netze}
}

@techreport{Ros57,
  title = {The Perceptron - {{A}} Perceiving and Recognizing Automaton},
  author = {Rosenblatt, F.},
  year = {1957},
  month = jan,
  number = {85-460-1},
  address = {{Ithaca, New York}},
  institution = {{Cornell Aeronautical Laboratory}}
}

@article{Ros58,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  author = {Rosenblatt, F.},
  year = {1958},
  journal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/h0042519}
}

@book{Ros62,
  title={Principles of neurodynamics: Perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, Frank},
  volume={55},
  year={1962},
  publisher={Spartan books Washington, DC}
}

@article{Ros60,
  title = {Perceptron {{Simulation Experiments}}},
  author = {Rosenblatt, Frank},
  year = {1960},
  journal = {Proceedings of the IRE},
  volume = {48},
  number = {3},
  pages = {301--309},
  doi = {10.1109/JRPROC.1960.287598}
}

@inproceedings{Sal90,
  title = {Beschleunigtes {{Lernen}} Durch Adaptive {{Regelung}} Der {{Lernrate}} Bei Back-Propagation in Feed-Forward {{Netzen}}},
  booktitle = {Konnektionismus in {{Artificial Intelligence}} Und {{Kognitionsforschung}}},
  author = {Salomon, R.},
  editor = {Dorffner, Georg},
  year = {1990},
  pages = {173--178},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  abstract = {Dieser Artikel besch\"aftigt sich mit back-propagation, einem Lernverfahren f\"ur Neuronale Netze. Es wird gezeigt, wie sich durch das Einf\"uhren von Testzyklen erstens eine starke Beschleunigung der Konvergenzgeschwindigkeit ergibt, und zweitens aufwendige Experimente, die zum Einstellen lernrelevanter Parameter dienen, entfallen k\"onnen.},
  isbn = {978-3-642-76070-9}
}

@article{SEJ+20,
  title = {Improved Protein Structure Prediction Using Potentials from Deep Learning},
  author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and {\v Z}{\'i}dek, Augustin and Nelson, Alexander W. R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
  year = {2020},
  month = jan,
  journal = {Nature},
  volume = {577},
  number = {7792},
  pages = {706--710},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1923-7}
}

@article{Sha38,
  title = {A Symbolic Analysis of Relay and Switching Circuits},
  author = {Shannon, Claude E.},
  year = {1938},
  journal = {Transactions of the American Institute of Electrical Engineers},
  volume = {57},
  number = {12},
  pages = {713--723},
  doi = {10.1109/T-AIEE.1938.5057767}
}

@article{Sha83,
  title = {The {{Fifth Generation Project}} \textemdash{} a {{Trip Report}}},
  author = {Shapiro, Ehud Y.},
  year = {1983},
  month = sep,
  journal = {Commun. ACM},
  volume = {26},
  number = {9},
  pages = {637--641},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  issn = {0001-0782},
  doi = {10.1145/358172.358179},
  abstract = {As part of Japan's effort to become a leader in the computer industry, the Institute for New Generation Computer Technology has launched a revolutionary ten-year plan for the development of large computer systems which will be applicable to knowledge information processing systems. These Fifth Generation computers will be built around the concepts of logic programming. In order to refute the accusation that Japan exploits knowledge from abroad without contributing any of its own, this project will stimulate original research and will make its results available to the international research community.}
}

@inproceedings{Sha86,
  title = {Donald {{Hebb}}: {{The Organization}} of {{Behavior}}},
  booktitle = {Brain {{Theory}}},
  author = {Shaw, G. L.},
  editor = {Palm, G{\"u}nther and Aertsen, Ad},
  year = {1986},
  pages = {231--233},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  abstract = {I consider this a great privilege to be able to briefly remark on D.O. Hebb's marvellous book ``Organization of Behavior: A Neuropsychological Theory'' which he wrote in 1949. Hebb's ideas have had a profound influence on brain theory, in particular his famous ``A Neurophysiological Postulate'' governing the correlated pre-post synaptic changes which are the basis for the engram or memory trace. Although, there are many different forms of Hebb's postulate, I believe that essentially all ``viable'' mammalian cortical models embody some version of his idea: ``Let us assume then that the persistence or repetition of a reverberatory activity (or ``trace'') tends to induce lasting cellular changes that add to its stability. The assumption can be precisely stated as follows:When an axon of cell A is near enough to excite cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A `s efficiency, as one of the cells firing B, is increased''.},
  isbn = {978-3-642-70911-1}
}

@article{Sha92,
  title = {The {{Developing Brain}}},
  author = {Shatz, Carla J},
  year = {1992},
  journal = {SCIENTIFIC AMERICAN},
  langid = {english}
}

@article{She13,
  title = {A Set of Five Independent Postulates for {{Boolean}} Algebras, with Application to Logical Constants},
  author = {Sheffer, Henry M.},
  year = {1913},
  journal = {Transactions of the American Mathematical Society},
  volume = {14},
  pages = {481--488}
}

@article{SHM+16,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and {van den Driessche}, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  year = {2016},
  month = jan,
  journal = {Nature},
  volume = {529},
  number = {7587},
  pages = {484--489},
  issn = {1476-4687},
  doi = {10.1038/nature16961},
  abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses `value networks' to evaluate board positions and `policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.}
}

@article{Sil10,
  title = {Neuronal Arithmetic},
  author = {Silver, R. Angus},
  year = {2010},
  month = jul,
  journal = {Nature Reviews Neuroscience},
  volume = {11},
  number = {7},
  pages = {474--489},
  issn = {1471-0048},
  doi = {10.1038/nrn2864}
}

@incollection{Son22,
  title = {Neuronale {{Netze}}},
  booktitle = {Neuronale {{Netze}} Kompakt: {{Vom Perceptron}} Zum {{Deep Learning}}},
  author = {Sonnet, Daniel},
  year = {2022},
  pages = {17--70},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-29081-8_2},
  abstract = {Neuronale Netze sind keine aktuelle Erfindung. Das Thema geht bis in die erste H\"alfte des vergangenen Jahrhunderts zur\"uck. Zu dieser Zeit gab es die Informatik wie in der heutigen Form noch nicht. Darum waren es keine Informatiker, die die Forschung um Neuronale Netze initialisierten, sondern Psychologen. In diesem Kapitel wird mit einem kompakten historischen Abriss gestartet. Alles begann mit dem sogenannten Perceptron, welches bereits erstaunliche approximative F\"ahigkeiten besa\ss{} und eine Disziplin innerhalb der k\"unstlichen Intelligenzforschung bildete. 1970, ausgel\"ost durch den sogenannten Lighthill Report erfuhr die KI-Forschung einen D\"ampfer, welcher den KI-Winter einl\"autete. Jeder Winter wird vom Fr\"uhling verdr\"angt, so auch hier. Mehr- bzw. tiefschichtige Netze (Deep Neural Networks) bilden heute den Status quo. Nach diesem historischen Abriss, der entscheidend zum Verst\"andnis dieser toller Disziplin ist, wird das Kapitel weitergef\"uhrt, indem ein paar unterschiedliche Lern- bzw. Trainingsverfahren Neuronaler Netze vorgestellt werden. Den Abschluss dieses Kapitels bildet ein Unterkapitel \"uber besonders erw\"ahnenswerte Netzwerktypen sowie ihre m\"oglichen Einsatzgebiete. In diesem Kapitel werden noch einmal wichtige Fachbegriffe er\"ortert und den einzelnen Netzwerktypen zugeordnet.},
  isbn = {978-3-658-29081-8}
}

@article{She26,
  title = {Principia Mathematica. {{Whitehead}}, Alfred North , Russell, Bertrand},
  author = {Sheffer, Henry M.},
  year = {1926},
  journal = {Isis; an international review devoted to the history of science and its cultural influences},
  volume = {8},
  number = {1},
  pages = {226--231},
  doi = {10.1086/358383}
}


@book{Squ13,
  title = {Fundamental Neuroscience},
  editor = {Squire, Larry R.},
  year = {2013},
  edition = {4th ed},
  publisher = {{Elsevier/Academic Press}},
  address = {{Amsterdam ; Boston}},
  isbn = {978-0-12-385870-2},
  langid = {english},
  lccn = {QP355.2 .F862 2013},
  keywords = {Neurosciences}
}

@incollection{SSH95,
  title = {Automaten},
  booktitle = {Automaten {{Sprachen Berechenbarkeit}}: {{Grundkurs Angewandte Informatik IV}}},
  author = {Sander, Peter and Stucky, Wolffried and Herschel, Rudolf},
  editor = {Stucky, W.},
  year = {1995},
  pages = {26--97},
  publisher = {{Vieweg+Teubner Verlag}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-322-84873-4_2},
  isbn = {978-3-322-84873-4}
}

@article{SST+20,
  title = {Fluid-Limiting Treatment Strategies among Sepsis Patients in the {{ICU}}: A Retrospective Causal Analysis},
  author = {Shahn, Zach and Shapiro, Nathan I. and Tyler, Patrick D. and Talmor, Daniel and Lehman, Li-wei H.},
  year = {2020},
  month = feb,
  journal = {Critical Care},
  volume = {24},
  number = {1},
  pages = {62},
  issn = {1364-8535},
  doi = {10.1186/s13054-020-2767-0},
  abstract = {In septic patients, multiple retrospective studies show an association between large volumes of fluids administered in the first 24\,h and mortality, suggesting a benefit to fluid restrictive strategies. However, these studies do not directly estimate the causal effects of fluid-restrictive strategies, nor do their analyses properly adjust for time-varying confounding by indication. In this study, we used causal inference techniques to estimate mortality outcomes that would result from imposing a range of arbitrary limits (``caps'') on fluid volume administration during the first 24\,h of intensive care unit (ICU) care.}
}

@incollection{Ste22,
  title = {Explainable {{AI}} Im {{Gesundheitswesen}}},
  booktitle = {K\"unstliche {{Intelligenz}} Im {{Gesundheitswesen}}: {{Entwicklungen}}, {{Beispiele}} Und {{Perspektiven}}},
  author = {Steinwendner, Joachim},
  editor = {Pfannstiel, Mario A.},
  year = {2022},
  pages = {755--767},
  publisher = {{Springer Fachmedien Wiesbaden}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-33597-7_36},
  isbn = {978-3-658-33597-7}
}




@book{Str01,
  title = {The {{Gale}} Encyclopedia of Psychology},
  editor = {Strickland, Bonnie B.},
  year = {2001},
  edition = {2nd ed},
  publisher = {{Gale Group}},
  address = {{Detroit, MI}},
  isbn = {978-0-7876-4786-5},
  langid = {english},
  lccn = {BF31 .G35 2001},
  keywords = {Encyclopedias,Psychology}
}

@misc{SVI+15,
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  year = {2015},
  doi = {10.48550/arXiv.1512.00567}
}

@article{SZJ+19,
  title = {Artificial {{Intelligence Versus Clinicians}} in {{Disease Diagnosis}}: {{Systematic Review}}},
  author = {Shen, Jiayi and Zhang, Casper J P and Jiang, Bangsheng and Chen, Jiebin and Song, Jian and Liu, Zherui and He, Zonglin and Wong, Sum Yi and Fang, Po-Han and Ming, Wai-Kit},
  year = {2019},
  month = aug,
  journal = {JMIR Med Inform},
  volume = {7},
  number = {3},
  eprint = {31420959},
  eprinttype = {pubmed},
  pages = {e10010},
  issn = {2291-9694},
  doi = {10.2196/10010}
}

@article{Szo88,
  title = {Artificial {{Intelligence}} in {{Medical Diagnosis}}},
  author = {Szolovits, Peter},
  year = {1988},
  journal = {Artificial Intelligence},
  volume = {108},
  number = {1},
  doi = {10.7326/0003-4819-108-1-80},
  langid = {english}
}

@inproceedings{Tap19,
  title = {Who {{Is}} the {{Father}} of {{Deep Learning}}?},
  booktitle = {2019 {{International Conference}} on {{Computational Science}} and {{Computational Intelligence}} ({{CSCI}})},
  author = {Tappert, Charles C.},
  year = {2019},
  pages = {343--348},
  doi = {10.1109/CSCI49370.2019.00067}
}

@article{TS81,
  title = {An Analysis of Physician Attitudes Regarding Computer-Based Clinical Consultation Systems},
  author = {Teach, Randy L. and Shortliffe, Edward H.},
  year = {1981},
  journal = {Computers and Biomedical Research},
  volume = {14},
  number = {6},
  pages = {542--558},
  issn = {0010-4809},
  doi = {10.1016/0010-4809(81)90012-4},
  abstract = {Physician attitudes regarding computer-based clinical decision aids and the effect of a 2-day tutorial on medical computing are studied. The results indicate that physicians are accepting of applications that enhance their patient management capabilities, but tend to oppose applications in which they perceive an infringement on their management role. Expectations about the effect of computing on current medical practices are found to be generally favorable, although considerable individual differences exist among subgroups. The study participants place substantial demands on the performance capabilities of acceptable consultation systems, and emphasize the need for humanlike interactive capabilities. The tutorial had no effect on attitudes regarding appropriate clinical uses of computers nor on expectations about the effect of the technology on medical practice. However, it did increase the participants' knowledge of medical computing and led to more informed demands on system performance. We discuss the implications of the study and offer suggestions for developing and implementing computer-based clinical decision aids.}
}

@article{Tuc86,
  title = {On Shunting Inhibition},
  author = {Tuckwell, H. C.},
  year = {1986},
  month = nov,
  journal = {Biological Cybernetics},
  volume = {55},
  number = {2},
  pages = {83--90},
  issn = {1432-0770},
  doi = {10.1007/BF00341923},
  %urldate = {2023-08-02},
  abstract = {The interaction between excitation and inhibition is analyzed for nerve cylinders when reversal potentials for synaptic action are included. Both impulsive and sustained conductance changes are employed to model synaptic action.},
  langid = {english},
  keywords = {Amplification Factor,Exact Result,Reversal Potential,Spatial Separation,Synaptic Action}
}

@article{Tur37,
  title = {On {{Computable Numbers}}, with an {{Application}} to the {{Entscheidungsproblem}}},
  author = {Turing, A. M.},
  year = {1937},
  journal = {Proceedings of the London Mathematical Society},
  volume = {s2-42},
  number = {1},
  pages = {230--265},
  doi = {10.1112/plms/s2-42.1.230}
}

@article{Ugu12,
  title = {A {{Biomedical System Based}} on {{Artificial Neural Network}} and {{Principal Component Analysis}} for {{Diagnosis}} of the {{Heart Valve Diseases}}},
  author = {U{\u g}uz, Harun},
  year = {2012},
  month = feb,
  journal = {Journal of Medical Systems},
  volume = {36},
  number = {1},
  pages = {61--72},
  issn = {1573-689X},
  doi = {10.1007/s10916-010-9446-7},
  abstract = {Listening via stethoscope is a primary method, being used by physicians for distinguishing normally and abnormal cardiac systems. Listening to the voices, coming from the cardiac valves via stethoscope, upon the flow of the blood running in the heart, physicians examine whether there is any abnormality with regard to the heart. However, listening via stethoscope has got a number of limitations, for interpreting different heart sounds depends on hearing ability, experience, and respective skill of the physician. Such limitations may be reduced by developing biomedical based decision support systems. In this study, a biomedical-based decision support system was developed for the classification of heart sound signals, obtained from 120 subjects with normal, pulmonary and mitral stenosis heart valve diseases via stethoscope. Developed system was mainly comprised of three stages, namely as being feature extraction, dimension reduction, and classification. At feature extraction stage, applying Discrete Fourier Transform (DFT) and Burg autoregressive (AR) spectrum analysis method, features, representing heart sounds in frequency domain, were obtained. Obtained features were reduced in lower dimensions via Principal Component Analysis (PCA), being used as a dimension reduction technique. Heart sounds were classified by having the features applied as input to Artificial Neural Network (ANN). Classification results have shown that, dimension reduction, being conducted via PCA, has got positive effects on the classification of the heart sounds.}
}

@book{SKM10,
  title = {Textbook of Drug Design and Discovery},
  editor = {Stromgaard, K. and Krogsgaard-Larsen, P. and Madsen, U.},
  year = {2010},
  edition = {4th ed.},
  publisher = {CRC Press},
  address = {{Detroit, MI}},
  isbn = {978-1-4200-6322-6},
  langid = {english}
}



@inproceedings{Van86,
  title = {Frank {{Rosenblatt}}: {{Principles}} of {{Neurodynamics}}: {{Perceptrons}} and the {{Theory}} of {{Brain Mechanisms}}},
  booktitle = {Brain {{Theory}}},
  author = {Van Der Malsburg, C.},
  editor = {Palm, G{\"u}nther and Aertsen, Ad},
  year = {1986},
  pages = {245--248},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  abstract = {Frank Rosenblatt's intention with his book, according to his own introduction, is not just to describe a machine, the perceptron, but rather to put forward a theory. He formulates a series of machines. Each machine serves to introduce a new concept.},
  isbn = {978-3-642-70911-1}
}

@incollection{Von11,
  title = {Einf\"uhrung},
  booktitle = {Glastechnische {{Fabrikationsfehler}}: ``{{Pathologische}}'' {{Ausnahmezust\"ande}} Des {{Werkstoffes Glas}} Und Ihre {{Behebung}}; {{Eine Br\"ucke}} Zwischen {{Wissenschaft}}, {{Technologie}} Und {{Praxis}}},
  author = {{Von Jebsen-Marwedel}, H.},
  editor = {{Jebsen-Marwedel}, Hans and Br{\"u}ckner, Rolf},
  year = {2011},
  pages = {3--15},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-16433-0_1},
  abstract = {Glas ist ein aus der Schmelze hervorgegangenes Produkt, das bei hohen Temperaturen eine stark ausgepr\"agte Z\"ahigkeit besitzt. Diese erlaubt seinen Strukturelementen (Tetraeder, Oktaeder) nicht, mit einsetzender Abk\"uhlung bei der Verarbeitungstemperatur den geordneten Zustand eines Kristallgitters anzunehmen, wie es bei anderen Stoffen, z.B. den Ionenkristallen oder Metallen der Fall ist, die beim Schmelzpunkt spontan kristallisieren. Glasschmelzen unterschreiten diese thermodynamisch kritische Zone und erstarren metastabil als unterk\"uhlte Fl\"ussigkeiten, die beim weiteren Abk\"uhlen ihre fl\"ussigkeits\"ahnliche Struktur einfrieren [1]. Sie bieten auch den Anblick einer als Fl\"ussigkeit von unendlich hoher Viskosit\"at verfestigten Substanz und stellen damit einen Sonderzustand der Materie dar, der auch schon \textendash{} etwas anspruchsvoll \textendash{} von Berger [2] als IV. Aggregatzustand bezeichnet wurde. Er befindet sich sozusagen zwischen der fluiden und der festen Beschaffenheit in der Schwebe. Das Glas hat gewisserma\ss en vers\"aumt, die allenfalls f\"allige Wandlung zur Kristallisation an sich zu vollziehen. Bild 1.1 gibt den Zusammenhang schematisch wieder. Die Glasschmelze durchl\"auft beim Abk\"uhlen den metastabilen Zustand der unterk\"uhlten Schmelze (Tammann [la]), um die Struktur im Einfrier bereich zu fixieren (Jenckel [1 c]) und anschlie\ss end in den instabilen Zustand des Glases \"uberzugehen (e \textendash{} f \textendash{} h in Bild 1.1).},
  isbn = {978-3-642-16433-0}
}

@incollection{von51,
  title = {The General and Logical Theory of Automata.},
  booktitle = {Cerebral Mechanisms in Behavior; the {{Hixon Symposium}}.},
  author = {{von Neumann}, John},
  year = {1951},
  pages = {1--41},
  publisher = {{Wiley}},
  address = {{Oxford,  England}},
  abstract = {A general outline of the ideas and trends in the application of artificial automata theory to living organisms and particularly the human central nervous system. The parts or elements of a system are treated as "black boxes" and their properties and functional regularities in combination are discussed. The material is organized under the major headings: Preliminary considerations, Discussion of certain relevant traits of computing machines, Comparisons between computing machines and living organisms, Future logical theory of automata, Principles of digitalization, Formal neural networks, Concept of complication; self-reproduction, and a general panel discussion included between the pages 32-41. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{Neu93,
  title = {First Draft of a Report on the {{EDVAC}}},
  author = {{von Neumann}, J.},
  year = {1993},
  journal = {IEEE Annals of the History of Computing},
  volume = {15},
  number = {4},
  pages = {27--75},
  doi = {10.1109/85.238389}
}

@article{Wur09,
  title = {Recounting the Impact of {{Hubel}} and {{Wiesel}}: {{Recounting}} the Impact of {{Hubel}} and {{Wiesel}}},
  shorttitle = {Recounting the Impact of {{Hubel}} and {{Wiesel}}},
  author = {Wurtz, Robert H.},
  year = {2009},
  month = jun,
  journal = {The Journal of Physiology},
  volume = {587},
  number = {12},
  pages = {2817--2823},
  issn = {00223751},
  doi = {10.1113/jphysiol.2009.170209},
  %urldate = {2023-09-05},
  langid = {english}
}

@book{Wie48,
  title = {Cybernetics; or Control and Communication in the Animal and the Machine.},
  author = {Wiener, Norbert},
  year = {1948},
  pages = {194},
  publisher = {{John Wiley}},
  address = {{Oxford,  England}}
}


@article{YLC+14,
  title = {Sleep Promotes Branch-Specific Formation of Dendritic Spines after Learning},
  author = {Yang, Guang and Lai, Cora Sau Wan and Cichon, Joseph and Ma, Lei and Li, Wei and Gan, Wen-Biao},
  year = {2014},
  journal = {Science},
  volume = {344},
  number = {6188},
  pages = {1173--1178},
  doi = {10.1126/science.1249098}
}



@inproceedings{ZSQ+17,
  title = {Pyramid {{Scene Parsing Network}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Zhao, H. and Shi, J. and Qi, X. and Wang, X. and Jia, J.},
  year = {2017},
  month = jul,
  pages = {6230--6239},
  publisher = {{IEEE Computer Society}},
  address = {{Los Alamitos, CA, USA}},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2017.660}
}
