---
id: index
title: "4. Neuronale Netze im Gesundheitswesen"
description: Neuronale Netze im Gesundheitswesen
---

import {R, F, S, EQ, Def, Tbl, initEq} from "../../../src/components/Refs.js";
import {Embed, Plot} from "../../../src/components/Embed.js";

_Pfannstiel_ stellt in <R>Pfa22, S. 35, Abb. 1.14</R> die Künstliche Intelligenz als Kern eines Schichtenmodells dar: Die vier umgebenden Schichten, von denen jede eine Menge repräsentativer Leistungen enthält, lassen sich grob einteilen in[^1]
 1. Versorgung des Patienten
 2. Herstellung / Zulieferung durch Pharmazie bzw. Medizintechnologie
 3. Organisation das Gesundheitswesen
 4. Selbstversorgung des Patienten

In jeder dieser Schicht übernimmt die KI wichtige Rollen, z.B. in der Diagnostik (1.), der Wirkstoffentwicklung (2.), der Abrechnung von Leistungen (3.) oder als Software in embedded Systems wie Wearables (4.). Zum Beispiel werden die in **Kapitel 3** vorgestellten CNNs aufgrund ihrer Erfolge bei der Objektklassifikation[^2] in der Diagnostik eingesetzt[^3]. Je nach Verfahren zeigt sich, dass die Netze mindestens genauso gute Diagnosen erstellen wie erfahrene Ärzte, und bessere als wenig erfahrene Ärzte (vgl. <R>SCJ+19, S.7</R> bzw. **Kapitel 4.3**). Doch auch in anderen Bereichen des Gesundheitswesens finden neuronale Netze praktische Anwendungen. Im Folgenden werden einige vorgestellt.

[^1]: Reihenfolge analog zu dem Modell in <R>Pfa22</R> von Innen nach Aussen
[^2]: vgl. <R>Ert21, S. 330</R>. _Goodfellow et al._ stellen etwas alle gemeiner fest, dass CNNs "gewaltige Erfolge in der Praxis gebracht" haben <R>GBC18, S. 369</R>. Als Beispiel sei PSPNet genannt, ein CNN zur semantischen Segmentierung von Bilddaten ("_scene parsing_"), das _Zhao et al_ in <R>ZSQ+17</R> vorstellen. Heutzutage betreiben Unternehmen wie Google, Facebook, Microsoft und IBM Forschung und Entwicklung im Bereich der Bildverarbeitung mit CNNs, und im Bereich Hardware entwickeln bspw. NVIDIA (https://nvidianews.nvidia.com/news/nvidia-introduces-drive-agx-orin-advanced-software-defined-platform-for-autonomous-machines, abgerufen 07.09.2023) und Samsung Chips zur Echtzeiterkennung der Umgebung  <R>LBH15, S. 440</R>.
[^3]: <R>BHU+18</R> stellt bspw. 13 Arbeiten zur Klassifikation von Hautläsionen mit der Hilfe von CNNs vor



## 4.1 Automatisierung in der Gesundheitswirtschaft
Um für die in Deutschland knapp 73 Millionen gesetzlich Krankenversicherten[^4] Leistungen im Gesundheitswesen abzurechnen, werden durch die Leistungserbringer Finanzdienstleister beauftragt. So leiten bspw. Apotheken eingelöste Kassenrezepte an Apothekenrechenzentren weiter, die die Abrechnungen mit den Krankenkassen durchführen. Obwohl Rezepte heutzutage überwiegend maschinell erstellt werden, kommt es bei den Rechenzentren nach der Digitalisierung der Rezepte (bspw. durch Scannen) häufig zu manueller Nachkorrektur, wenn abrechnungsrelevante Daten nicht vollständig erfasst werden können, wie _Höfer et al._ in <R>HWN22</R> feststellen. Um den zusätzlichen Arbeitsaufwand durch Nachkorrekturen zu reduzieren (aufgrund von Störfaktoren wie ausgedünnte Zeichen oder Textüberlagerungen), stellen sie ein neuronales Netz vor, das bei einem führenden Abrechnungszentrum für Apotheken eingesetzt wird. Ziel des Netzes ist die Rekonstruktion[^5] von Rezepten, die bei Plausibilitätskontrollen auffällig sind.<br />
Ihr neuronales Netz zur Rekonstruktion von Rezepten ist ein CNN mit 7 Faltungsschichten, denen jeweils eine Poolingschicht folgt. Insgesamt werden 40.000 Datensätze für das Training genutzt, sowie 10.000 Validierungsdatensätze. Die Rezepte werden auf den für die Abrechnung relevanten Teil zugeschnitten, sodass die Eingabedaten aus $720 \times 460$ Pixeln bestehen. Sie zeigen, dass Ihr Netz  bei der Rekonstruktion von Korrekturzeichen eine relative Verbesserung von 27,85% erreicht[^6] und aufgrund dieses Erfolges das System in den praktischen Workflow des Abrechnungszentrums integriert wurde.

[^4]: https://www.gkv-spitzenverband.de/krankenversicherung/kv_grundprinzipien/alle_gesetzlichen_krankenkassen/alle_gesetzlichen_krankenkassen.jsp, abgerufen 12.09.2023
[^5]: tatsächlich liegt die Vermutung nahe, das Netz sollte eingesetzt werden, um den Hochleistungsscanner zu ersetzen. Ziel war es aber, in einem Vorverarbeitungsschritt die Bildqualität zu erhöhen <R>HWN22, S. 698</R>
[^6]: 5% waren ursprünglich anvisiert <R>HWN22, S. 711</R>


## 4.2 Pharmaforschung
Im Jahr 2016 gelingt es der von _Google DeepMind_ entwickelten Software _AlphaGo_, den Südkoreaner Lee Sedol als einen der weltbesten _Go_-Spieler in ebendiesem Spiel zu schlagen[^6]. _Go_ verfügt über $2,08 \times 10^{170}$ gültige Spielpositionen und gehört damit zu den komplexesten Brettspielen der Welt[^7]. Kurz nach diesem beachtlichen Erfolg entscheidet _Google DeepMind_, dass das in der Software verwendete 13-lagige CNN-Netz mit seiner $19 \times 19$ Eingabe- und Ausgabematrix sowie trainiert mit über 30 Millionen Spielzügen<R>Ert21, S. 371</R>, reif sei für den Einsatz in der Wissenschaft. Im selben Jahr beginnt das Unternehmen mit der Forschung an _AlphaFold_<R>JEP+21</R>[^8]: Die Software soll helfen, das Problem der **Proteinfaltung** zu vereinfachen: Darunter versteht man die Vorhersage der Struktur eines Proteins auf Basis seiner Aminosäuresequenz  <R>DOSW08</R>[^9]; mit $10^{300}$ verschiedenen Konstellationen[^10] ist die Struktur sichtlich schwer zu berechnen.<br />
Grossen Erfolg hat die Software 2020 bei dem CASP14-protein-folding-contest[^11]. Mit 170.000 Proteinstrukturen trainiert und von ~ 200 GPUs unterstützt erreicht AlphaFold2 Bestwerte[^12], was als Durchbruch für die Medizin bewertet wird <R>Cal20, S. 204</R>. Der Pharmaindustrie erlaubt das Wissen über die Struktur von Proteinen die Herstellung von Medikamente, deren Wirkstoffe bspw. die Proteinfunktionen aktivieren oder hemmen[^13].

[^6]: https://www.spiegel.de/netzwelt/gadgets/go-duell-software-alphago-siegt-gegen-lee-sedol-a-1081975.html, abgerufen 08.09.2023
[^7]: https://tromp.github.io/go/legal.html, abgerufen 08.09.2023
[^8]: https://www.deepmind.com/research/highlighted-research/alphafold/timeline-of-a-breakthrough, abgerufen 08.09.2023
[^9]: postuliert 1972 von _Anfinsen_ in seiner Nobelpreislaudatio  <R>Anf72, S. 56 Abs. 2</R>
[^10]: https://web.archive.org/web/20110523080407/http://www-miller.ch.cam.ac.uk/levinthal/levinthal.html, abgerufen 08.09.2023
[^11]: CASP (Critical Assessment of Techniques for Protein Structure Prediction), ein seit 1994 alle zwei Jahre stattfindender Wettbewerb zur Vorhersage von Proteinstrukturen (https://predictioncenter.org/ , abgerufen 08.09.2023)
[^12]: mit einem Score von 92.4 GDT. In den Jahren vor AlphaFold lag der Score bei ca. ~ 30-40 GDT. GDT bedeutet _global distance test_ mit einem Wertebereich zwischen 1 und 100 und gibt die Ähnlichkeit einer Proteinstruktur mit der Struktur eines Vergleichsmodells an (
https://proteopedia.org/wiki/index.php/Calculating_GDT_TS, abgerufen 09.09.2023)
[^13]: Bei dem strukturbasierten Wirkstoffdesign hilft die Kenntnis über die Struktur des Zielproteins bei der Entwicklung von Medikamenten, deren Moleküle zur Wirkstoffentfaltung an die Proteine andocken <R>SKM10, S. 29 ff.</R>



## 4.3 Diagnostik
_Szolovits et al._ argumentieren 1988 in <R>SPS88</R>, dass die Abfrage von Symptomen zur Feststellung von Krankheiten[^14] auch von Expertensystemen (siehe **Kapitel 3.1**) übernommen werden kann. Allerdings zeigt sich ebenfalls, dass Ärzte kritisch gegenüber computergestützten Assistenzsystemen stehen. _Teach und Shortliffe_ führen bereits 1981 aus, dass es medizinischem Fachpersonal wichtig ist, dass das System den Entscheidungsweg zur Diagnose erklären kann; dass der Computer stets die korrekten Diagnosen stellt, wird als weniger wichtig bewertet <R>TS81, S. 551, "Table V", "D.1" sowie "D14"</R>. In dieser Studie[^15] werden auch ethische Bedenken seitens der Mediziner aufgeführt. Dass computergestützte medizinische Assistenzsysteme dann kaum Anwendung im klinischen Umfeld fanden, führen _Lucieri et al._ auch auf solche Bedenken zurück: Erst steigende Rechenleistung und die fortschreitende Leistungsfähigkeit tiefer neuronaler Netze weckte das Interesse an KI unter den Medizinern, dank der Erfolge bildbasierter CNNs auch in der Diagnostik <R>LBDA22, S. 728</R>. Dem oben erwähnten Wunsch einer **erklärbaren KI** (**xAI** [^16]) wird seitdem nachgegangen, erweist sich aufgrund des _Blackbox-Charakters_[^17] insb. bei Architekturen mit Millionen von Parametern[^18] in neuronalen Netzen aber als schwierig[^19].<br />
Trotz allem ist nicht von der Hand zu weisen, dass neuronale Netze in der Qualität der Diagnosen gleichauf sind mit denen von medizinischem Fachpersonal <R>SCJ+19</R>. _Amato et al._ <R>ALP+13</R> listen unter anderem Studienergebnisse bzgl. des Einsatzes neuronaler Netze bei der Diagnostik von kardiovaskulären Krankheiten, Tumor-Erkrankungen sowie Diabetes auf, und kommen bei der Auswertung zu dem Ergebnis, das die neuronalen Netze bei einer Vielzahl verschiedener Symptomatiken die korrekte Diagnose erstellen: Zum Beispiel werden Audioaufnahmen der Pumptätigkeit des Herzens zur Klassifizierung von Herzklappenfehler genutzt, bei dem das eingesetzte Netz - ein MLP mit 3-Schichten unter Verwendung von Backpropagation - eine Erfolgsrate von knapp 95% vorweisen kann <R>Ugu12</R>.<br /> In <R>EKN+17</R> trainieren _Estava et al._ ein CNN basierend auf _GoogleNet Inception v3_[^20] mit über 1.000.000 Bildern aus 1000 verschiedenen Kategorien, um danach über _transfer learning_[^21] mit 129.450 gelabelten Bilddateien aus 2032 verschiedenen Krankheiten ein Netz zur Diagnose von Hautkrebs zu erstellen. Sie zeigen, dass das Netz bei der Korrektheit der gestellten Diagnosen genauere Diagnosen erstellt als ein Mediziner[^22]. <br />
_Irving et al._ stellen in <R>IRK+19</R> "CheXpert"[^23] vor, einen öffentlichen Datensatz mit 224.316 Aufnahmen des Thorax von 65.240 verschiedenen Patienten zur Klassifizierung von 14 Befunden (u.a. Lungenentzündung, Fraktur, Pleuraerguss). Für das Training nutzen sie _DenseNet121_, ein CNN, in dem jede Schicht mit jeder anderen verbunden ist <R>HLW16</R>[^24]. Die Inputdaten bestehen aus $320 \times 320$ Pixeln. Bei den Tests zeigt sich, dass ihr Netz bei der Diagnostizierung von Kardiomegalie, Ödemen sowie Pleuraergüssen besser abschneidet als die in der Studie eingesetzten Radiologen[^25].


[^14]: bei gleichzeitigem Ausschluss anderer Krankheiten
[^15]: In dem Papier findet sich auch die Befürchtung unter den Teilnehmern an der Umfrage, dass computer-gestützte Systeme den Arzt ersetzen könnte <R>TS81, S. 543</R>
[^16]: Abkürzung für (engl.) _explainable AI_
[^17]: **AlexNet**: 60.000.000 Parameter <R>KSH12</R>
[^18]: https://spectrum.ieee.org/ai-failures, abgerufen 09.09.2023
[^19]: Einige erfolgreiche Ansätze jüngster Zeit fassen _Lucieri et al._ in <R>LBDA22, S. 733 ff.</R> zusammen. _Steinwender_ geht in <R>Ste22</R> auf die Zertifizierungspflicht von Medizinprodukten in der EU ein, und das mit der damit verbundenen Datenschutzgrundverordnung auch eine Interpretierbarkeit bzw. Erklärbarkeit für die KI-Systeme einhergeht
[^20]: Im Vergleich zu **AlexNet** nur 5.000.000 Parameter, aber erreicht bei der Bildklassifizierung bessere Werte als andere Modelle <R>SVI+15</R>. Eine interessanten Diskussionsgrundlage zu den Ausführungen in <R>Cun89</R> (s. **Kapitel 3.2.4**).
[^21]: beim _transfer learning_ werden semantisch gleiche Ausgaben für verschiedenklassige Eingaben genutzt <R>RN09, S. 602 ff.</R>
[^22]: "The deep learning CNN outperforms the average of the dermatologists at skin cancer classification using photographic and
dermoscopic images" <R>EKN+17, S. 3, "Figure 3"</R>
[^23]: https://stanfordmlgroup.github.io/competitions/chexpert/, abgerufen 10.09.2023
[^24]: DenseNet: Dense Convolutional Network. In klassischen CNNs mit $L$ Schichten existieren $L$ direkte Verbindungen, also eine Verbindung für eine obere und die darunterliegende Schicht. Durch die Architektur von _Densenet_ existieren in dem Netz $L(L +1)/2$ direkte Verbindungen.
[^25]: https://intermountainhealthcare.org/news/2019/09/ai-system-accurately-detects-key-findings-in-chest-x-rays-of-pneumonia-patients-within-10-seconds/ (abgerufen 10.09.2023) fasst die Ergebnisse bei der Diagnose von Lungenentzündung zusammen

## 4.4 Therapie und Prognose

Die _HL7_-Organisation[^26] wurde 1987 mit dem Ziel gegründet, einen Kommunikationsstandard für den elektronischen Datenaustausch im Gesundheitswesen zu etablieren. Teil des Standards ist die _FHIR_-Spezifikation[^27], die von _Rajkomar et al._ in <R>RCD+18</R> für ein neuronales Netz genutzt wird, das für einen mit diesen Daten verknüpften Patienten bei der Hospitalisierung Vorhersagen über folgende Punkte stellt:
 - Mortalität während des Krankenhausaufenthaltes ("inpatient mortality")
 - ungeplante stationäre Wiederaufnahme ("unexpected readmissions within 30 days")
 - Verlängerung des Aufenthaltes ("long length of stay")
 - Befund bei Entlassung ("discharge diagnoses")

Validiert wurde das Netz über insg. 46.864.534.945 Datenpunkte: Die von verschiedenen Krankenhäusern zur Verfügung gestellten 216.221 Patietenakten wurden hierzu aufgeteilt in 194.470 Trainingsdaten und 21.751 Testdaten, allesamt im FHIR-Format. Die Autoren des Papiers konnten zeigen, das ihr Netz die traditionellen klinischen Modelle in den ersten 3 genannten Punkten übertrifft. Eine ähnliche Arbeit stellen _Choi et al._ in <R>CBS+16</R> vor, in der sie untersuchen, ob elektronische Patientendaten genutzt werden können, um mit Hilfe rekurrenter neuronaler Netze Vorhersagen zu Diagnose, Medikation und Wiedervorstellung beim Arzt zu treffen. Sie zeigen, dass ihr Netz als medizinisches Assistenzsystem in den aufgeführten Punkten geeignet ist, und darüber hinaus mittels _transfer learning_[^21] in Kliniken eingesetzt werden kann, bei denen die Datenmenge nicht für ein Training des Netzes ausreicht. <br />
Prognosemodelle werden auch auf anderer Ebene genutzt, bspw. bei der Evaluierung der korrekten Behandlungsmethode. In <R>LHL+21</R> stellen _Li et al._ _G-Net_ vor, ein Deep Learning Framework für "counterfactual prediction" als Assistenzsystem für Ärzte. Es soll dabei helfen, unter Berücksichtigung von zur Verfügung stehenden Daten wie Therapie- und Krankheitsverlauf der Patienten die richtige Behandlungsstrategie auszuwählen. Unter "counterfactual prediction" sind hier alternative Szenarien gemeint, also das Ergebnis einer zunächst in der Theorie eingeschlagenen Therapie, für die von der Software das Behandlungsergebnis ermittelt wird[^28]. Als Beispiel führen _Li et al._ die Flüssigkeitszufuhr zur Stabilisierung von Intensivpatienten an, die einen septischen Schock erlitten haben. Anwendungszeitpunkt-, -art und -menge bestimmen den Genesungsverlauf und können unerwünschte Nebenwirkungen verhindern, allerdings auch solche begünstigen, die bis hin zum Tode führen <R>ZST+20</R>. Die in _G-Net_ verwendeten Netze sollen dabei helfen, in Verbindung von Parametern wie Laborwerte des Patienten sowie Zeitpunkt und Menge der Verabreichung eine Aussage über den Behandlungseffekt zu treffen[^29], um so die bestmögliche Behandlungsmethode auszuwählen.

[^26]: "Health Level Seven" https://hl7.org, abgerufen 11.09.2023
[^27]: "Fast Healthcare Interoperability Resources", https://hl7.org/fhir/, abgerufen 11.09.2023
[^28]: "This is particularly important in clinical settings, where physicians may have to choose between multiple treatment strategies for their patients but are unable to test all of them before making a decision"  <R>LHL+21, S. 282</R>
[^29]: unter https://news.mit.edu/2022/deep-learning-technique-predicts-clinical-treatment-outcomes-0224 (abgerufen 10.09.2023) ist eine ausführlichere Pressemitteilung mit Verweis auf das zitierte Papier


#### Notes

- In spite of these huge successes, ‘deep learning’ techniques have not yet made a big impact on the field of medical imaging. One of the main reasons is that for the traditional imaging based specialties (e.g. radiology) the large numbers of images that are needed to train complex ‘deep learning’ systems are not readily available. In digital
histopathology this is easier: one WSI typically contains trillions of pixels from which hundreds of examples of
cancerous glands (in the case of prostate or breast cancer) can be extracted. [LST+16]


- Deep Learning erstellt bessere Diagnosen als Ärzte [ERT21, p. 343]: ESTEVA, KUPREL, NOVOA: Dermatologist-level classificarion of skin cancer with deep neural networks, Nature 542 (2017); LITJENS, SANCHES, TIMOFEEVA: Deep Learning as a toll for increased accuracy and efficiency of histopathological diagnosis, Nature Scientific Reports 6 (2016)

- Russel Norvig Umgebung Bildanalyse deterministisch p. 72, medizinische Diagnose

- Bildsegmentierung, bspw um Organe (Umriss) zu erkennen
- Physikalische Simulation: Unberath: DeepDDR https://deepdrr.readthedocs.io/README.html Röntgenbildgebung
- Wang: image reconstruction is a new frontier if machine learning IEEE transactions on medical imaging: https://ieeexplore.ieee.org/document/8359079
- Deep Learning: Datenhungrig (PFANN, 694), deshalb: https://grand-challenge.org, Spenden medizinischer Daten (https:// medicaldatadonors.org)
- Ronneberger: Convolutional networks for biomedical image segmentation

- https://www.ki.fau.de/ki-in-der-medizin/, auch andere Universitätskliniken recherchieren: Charite Berlin, UK Aachen, UK ULM, München

- Explainable AI Bezug nehmen mit Aussage [Ert21., S. 344]