---
id: index
title: "3. Neuronale Netze in der Medizin"
description: tbd
---

import {R, F, S, EQ, Def, Tbl, initEq} from "../../../src/components/Refs.js";
import {Embed, Plot} from "../../../src/components/Embed.js";


## 3.1 Renaissance der neuronalen Netze

Der Begriff "KI Winter" wird in der Literatur mit unterschiedlichen Perioden während der Forschung und Förderung von KI in Zusammenhang gebracht. In dem Kontext des im vorherigen Kapitel erwähnten Lighthill Reports bezieht sich der Begriff einerseits auf die Periode nach 1973[^1] <R>Jon08, S. 8 f.</R>; _Russell und Norvig_ beziehen sich hingegen auf einen Zeitraum um/ nach 1988, in dem nach einer Phase von Investitionen in Milliardenhöhe in den Forschungszweig "viele Unternehmen verschwanden, weil sie ihre außergewöhnlichen Versprechungen nicht halten konnten." <R>RN09, S. 48, 1.3.6 letzter Abs.</R>[^2].

In den 80er Jahren sahen die großen Industrienationen in der Erforschung von KI einen Wettbewerbsvorteil, nachdem die Technologie durch den Einsatz von Expertensystemen[^3] Einzug in die Wirtschaft gefunden hatte: So ermöglichte das Expertensystem[^4] R1/XCON bei dem einsetzenden Unternehmen DEC (Digital Equipment Corporation) Einsparungen in Millionenhöhe[^5] <R>RN, S. 48</R>: Die Domäne von R1 war die regelbasierte Konfiguration von VAX-11/780 Systemen nach Kundenanforderungen[^6]. Japan kündigte 1981 das 5th Generation Projekt <R>Gar19</R> an, einen Zehnjahresplan für den Aufbau "intelligenter Computer" <R>RN09, S. 48, Abs. 2</R>[^7], und in Großbritannien sorgte der Alvey-Report[^8] für eine Wiederaufnahme finanzieller Unterstützung, die durch den Lighthill-Report aufgehoben worden war <R>RN09, S. 48, Abs. 2</R>[^9].

Auch der technologische Fortschritt begünstigte das Wiederaufleben des Interesses an neuronalen Netzen, wie _Olazaran_ in  in Bezug auf die Modellierung paralleler Prozesse mit Hilfe von neuronalen Netzen anmerkt: "[...] increases in computer power and speed due to parallelism will undoubtedly favour neural net research.", denn mit den in den 80er Jahren verfügbaren Supercomputern und Parallelrechner[^10] erhält auch der Konnektionismus Auftrieb, der **neuronale Netze** als Grundlage hat <R>Dor91, S. 15</R>, und mit dem sich Modelle wieder mehr an den biologischen Vorbildern orientieren sollten (vgl. <R>RM87, S. 43, Abs. 3</R> sowie <R>GBC18, S.18-19</R>).


[^1]: sowie "Lighthill's report provoked a massive loss of confidence in AI by the academic establishment in the UK (and to a lesser extent in the US). It persisted for a decade - the so-called 'AI Winter'." (aus: Jim Howe, Artificial intelligence at edinburgh university: A perspective, https://www.inf.ed.ac.uk/about/AIhistory.html, abgerufen 31.08.2023).
[^2]: auf gleichen Zeitraum bezieht sich <R>Mcc04, S. 432 ff.</R>; vgl. hierzu auch <R>Gar19, S. 656</R>: "Dozens of expert systems companies and AI-focused hardware manufacturers failed _en masse_ as hype turned to disillusionment." (Hervorhebungen i.O.)
[^3]: 1990 in <R>FS90, S. 14, "1.4 Expertensysteme"</R> als "kommerziell erfolgreichste Teildisziplin der Artificial intelligence" bezeichnet, und ebenda beschrieben als: "Ziel der Expertensysteme ist es, dem Anwender Wissen und Fertigkeiten zur Verfügung zu stellen, über die normalerweise nur speziell ausgebildete oder erfahrene Personen (Experten) verfügen." Im groben besteht ein Expertensystem aus einer domänenspezifischen _Wissensbasis_, auf der ein _Inferenzmotor_ zur Findung von Antworten und Schlussfolgerungen operiert. <R>RN09, S. 737</R> erklärt, dass Expertensysteme "optimale Entscheidungen empfehlen und dabei die Prioritäten des Benutzers sowie die verfügbaren Evidenzen berücksichtigen".
[^4]: das "erste erfolgreiche kommerzielle Expertensystem" <R>RN09, S. 48, Abs. 1</R>
[^5]: Die Domäne von R1 war die Konfiguration von DECs VAX-11/780 basierend auf Kundenanforderungen <R>Mcd80</R>
[^6]: siehe hierzu insb. <R>Mcd80</R> sowie <R>Hor90, S. 63, Punkt 2</R>
[^7]: Zusammenfassend war das Ziel des 5th Generation Computer Systems (FGCS)-Projekt: "Its ultimate goal is to develop integrated systems, both hardware and software, suitable for the major computer application in the nextdecade, identified by the Japanese as 'knowledge information processing'." in <R>Sha83, S. 637, Anführungszeichen i.O. doppelt</R>
[^8]: https://www.chilton-computing.org.uk/inf/literature/reports/alvey_report/overview.htm - empfohlene Massnahmen: https://www.chilton-computing.org.uk/inf/literature/reports/alvey_report/p008.htm (beide abgerufen 31.08.2023)
[^9]: In Deutschland wird 1988 die DFKI GmbH (Deutsches Forschungszentrum für Künstliche Intelligenz) gegründet, eine "wirtschaftsnahe Forschungseinrichtung" auf "dem Gebiet innovativer Softwaretechnologien auf der Basis von Methoden der Künstlichen Intelligenz" (https://www.dfki.de/fileadmin/user_upload/DFKI/Medien/Ueber_uns/DFKI_im_UEberblick/Unternehmensprofil/20210120_DFKI_Unternehmensprofil_DE.pdf, abgerufen 31.08.2023)
[^10]: Auch _Fausett_ nennt bessere Rechenleistung als einen Grund für den erneuerten Enthusiasmus <R>Fau94, S. 26</R>. Im Kontext der in diesem Kapitel vorgestellten mehrschichtigen Netzen und ihrem Konzept der versteckten Schichten ist nachvollziehbar, das mehr Rechenleistung den komplexen Verfahren entgegenkommt. _Goodfellow, Bengio und Courville_ gehen auf die Korrelation Modellgrösse und Anzahl der Nervenzellen in einem menschlichen Gehirn (vgl. Fussnote 15 in **Kapitel 1.2**) in <R>GBC18, S. 24 ff.</R> ein

## 3.2 Mehrschichtige neuronale Netze

Bislang haben wir überwiegend künstliche Neuronen betrachtet, bei denen die Eingabe direkt mit der Ausgabe verbunden ist. Allerdings haben wir bereits für komplexe Boolesche Funktionen in Kapitel 2.1.3.3 gezeigt, dass ein Verbund von mehreren MCP-Zellen in der Lage ist, auch Funktionen für nicht linear separable Daten zu modellieren. Hierzu hatten wir das MCP-Netz in zwei Schichten aufgeteilt, in denen die erste Schicht $X_1 := (\neg A \lor B)$ sowie $X_2 := (\neg B \lor A)$ und die zweite Schicht $X_1 \lor X_2$ formt, was nichts anderes als die disjunktive Normalform von XOR ist (**_2-1-6_**).

Bei dem Rosenblatt-Perzeptron, das alleine nicht in der Lage ist, XOR zu erlernen, handelt es sich um ein **Einschichtiges neuronales Feedforward-Netz**. Das bedeutet, dass es nur Eingabe und Ausgabe gibt und die Informationen ausschliesslich in Richtung Ausgang fliessen <R>RN09, S. 848 ff.</R>.

Allerdings ist auch ein **mehrschichtiges Perzeptron** (MLP, _multi-layer perceptron_) <R>GBC18, S. 6</R> in der Lage, nicht linear-separable Daten zu klassifizieren. Ein MLP repräsentiert ein tiefes Feedforward-Netz, in dem die Eingabeschicht (**Input Layer**) und die Ausgabeschicht (**Output Layer**) über weitere Schichten von Neuronen (**hidden layer**) verbunden ist; die Neuronen in diesen Schichten implementieren Eingabe- und Aktivierungsfunktion und leiten ihre Berechnungen an die nächsten Zellen bis zu der Ausgabeschicht weiter. _Murtagh_ zeigt in <R>Mur91, S. 185</R> die Modellierung von XOR anhand eines MLPs.

**Abb. 3.1**: Skizze eines mehrschichtigen neuronalen Feedforward-Netzwerks.

### 3.2.1 Backpropagation
An gleicher Stelle demonstriert _Murtagh_ ein MLP, das mittels **Backpropagation**[^11] Daten klassifiziert, die keinen linearen Zusammenhang besitzen. Hierbei bezieht er sich auf _Rumelhart, Hinton und Williams_ die in <R>RHW86a</R> eine Methode[^12] vorstellen, um berechnete Werte _rückwärts_ in das Netz einzuspeisen. Hierbei wird für die Netzausgabe ("forward pass") ein Approximationsfehler berechnet, der als Basis für die Gewichtsänderungen beim rückwärtigen Lauf ("backward pass") bis zur ersten verborgenen Schicht genutzt wird. Der Vorgang (forward pass, backward pass, forward pass...) wird so lange für alle Trainingsbeispiele wiederholt, bis die Gewichte sich nicht mehr ändern, oder eine andere Schranke (Epochen, Zeit) erreicht ist <R>Ert21, S. 315</R>[^13].

Die mathematische Basis für Backpropagation ist das **Gradientenabstiegsverfahren**, das hilft, in einem neuronalen Netz Parameter für möglichst optimale Verlust-Werte (also geringe Fehler-Werte) zu finden <R>RN09, S.837</R> (Abb. 3.3).  Ausserdem unterstützt die **Sigmoid**[^14]-Funktion als Aktivierungsfunktion[^15] (Abb. 3.2) aufgrund ihres nicht-linearen Charakters eine größere Klasse darstellbarer Funktionen und damit Lösungen für Probleme, die ein klassisches Perzeptron nicht lösen kann (vgl. <R>Ert 21, S.316</R>)[^16] [^17].

<EQ id ="3-2-1">

Sigmoidfunktion

</EQ>


**Abb. 3.2** Ein Plot der Sigmoid-Funktion


**Abb. 3.3** Informelle Darstellung des Gradientenabtiegsverfahrens. Die y-Achse repräsentiert die Anzahl der Fehler, die x-Achse den berechneten Gewichtsvektor in einem neuronalen Netz. Offensichtlich exiatiert in dem Netz ein optimaler Wert für w, der mittels Gradientenabstieg gefunden werden soll (vgl. <R>Son22 S. 52</R>.

[^11]: "das meist genutzte neuronale Modell" <R>Ert21, S. 313, "9.5 Der Backpropagation Algorithmus"</R>
[^12]: "The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure." <R>RHW86b, S. 533</R>
[^13]: ausführlicher Algorithmus in <R>RN09, S. 853, Abbildung 18.24</R>
[^14]: _sigmoid_: "Sigma", griechischer Buchstabe $\Sigma$, entspricht dem lateinischen "S"; "_eidos_" (griechisch) Form, Gestalt
[^15]: "Historisch wurde Backpropagation mit der Sigmoidfunktion implementiert." <R>Ert21, S. 314, Fussnote 4</R> In Kapitel 9.5.3 (vgl. <R>RHW86a, S. 329, (15)</R>). _Ertel_ fügt hinzu: "Mittlerweile haben sich jedoch andere Funktionen als besser bewährt." In <R>Ert21, S. 319</R> geht der Autor auf "Probleme und Verbesserungen" des mittlerweile über 30 Jahre alten Verfahrens ein. <R>GBC18, S. 19</R>  stellt fest, dass Backpropagation der "vorherrschende Ansatz für das Training tiefer Modelle" (im Jahr 2018) ist.
[^16]: In <R>RM86a</R> zeigen _Rumelhart, Hinton und Williams_ die Architektur eines mehrschichtigen neuronalen Netzes, das XOR über Backpropagation repräsentiert. Gleichzeitig grenzen sie in <R>RHW86b, S. 536</R> ihr Modell vom biologischen Lernen ab: "The learning procedure, in its current form, is not a plausible model of learning in brains".
[^17]: _Ertel_ weist darauf hin, dass die Klasse der darstellbaren Funktionen erhöht wird, wenn man für ein Perzeptron eine variable Sigmoid-Funktion verwendet <R>Ert21, S. 316, Abs. 2</R>. Siehe hierzu auch "Sigmoid-Perzeptron" in <R>RN09, S. 847</R>

In den 80er Jahren werden neben dem Backpropagation-Algorithmus weitere Entwürfe für neuronale Netze erstellt, die für ein Wiederaufleben des Interesses an der transdisziplinären Wissenschaft sorgen vgl(<R>Fau94, S. 25 ff.</R>).

### 3.2.2 Hopfield-Netz

Der Physiker John J. Hopfield (1933 -) stellt 1982 in <R>Hop82</R> ein Modell für ein _asynchrones_[^18] neuronales Netz vor, das auf neurobiologischen Aspekten <R>Hop82, S. 2554</R> beruht und 5 Jahre später in Zusammenarbeit mit At & T Bell Laboratories[^19] in Form eines "neural network chip"[^20] <R>AR88, S. 457</R> als Hardware umgesetzt wird: Das Modell ist ein **rekurrentes Netz**[^21] ohne Schlingen ($w_{ij} = 0$)[^22] <R>Ert21, S. 291</R> mit bidirektionalen symmetrischen Kanten ($w_{ij} = w_{ji}$) und fungiert als **Assoziativspeicher**, also als Netz, das, wenn es für eine Eingabe $x$ die Ausgabe $y$ liefert, $y$ auch für $x'$ berechnet, sofern $x'$ nahe genug bei $x$ liegt[^23] <R>Roj93, S. 251</R>, was das Netz gegenüber _Rauschen_ und _Störungen_[^24] resistenter macht.<br />
_Ertel_ führt die Begeisterung für neuronale Netze und den Aufschwung der Neuroinformatik in den 80er Jahren wesentlich auf die "biologische Plausibilität, das gut verstandene mathematische Modell" und "die beeindruckende Simulation zur Mustererkennung" auf das Hopfield Modell zurück <R>Ert21, S. 297</R>. _Anderson und Rosenfeld_ bemerken, dass der Einfluss physikalischer Systeme auf das Hopfield Netz auch das Interesse der Physiker an neuronalen Netzen geweckt hat, und dadurch das Forschungsfeld erweitert wurde (vgl. <R>AR88, S. 458</R>). Dies ist darauf zurückzuführen, dass sich die Summe aller Terme in einem Hopfield-Netz wie folgt berechnet (vgl. <R>Roj93, S.287</R>[^25])

<EQ id ="3-2-2">

$E = -1/2 * \sum^n_{i=1}\sum^n_{j=1} w_{ij}x_ix_j + \sum^n_{i=1}\Theta_ix_i$

</EQ>

Dies wird auch als die **Energiefunktion** des Netzes bezeichnet, wobei $E$ entweder konstant bleibt oder kleiner wird - aber nicht größer: Ist in einem Netz eine solche Energiefunktion vorhanden, kann gezeigt werden, das das Netz konvergiert <R>Fau94, S. 139</R>, und zwar hin zu einem Zustand _minimaler Energie_: _Ertel_ erklärt hierzu, dass gelernte Muster in dem Netz "Minima der Energiefunktion im Zustandsraum" darstellen; werden zuviele Muster gelernt, "konvergiert das System gegen Minima, die keinen gelernten Muster entsprechen". Damit ist das Modell "formal äquivalent zu einem physikalischen Modell des Magnetismus" <R>Ert21, S. 293</R>[^26], wo ebenfalls solche _Phasenübergänge_ von einem geordneten hin zu einem chaotischen System beobachtet werden können[^27].

_Ackley, Hinton und Sejnowski_ stellen 1985 in <R>AHS85</R> die **Boltzmann-Maschine**[^28] vor, eine Modifikation eines Hopfield-Netzes, in dem sich die Zellen _stochastisch_ <R>AR88, S. 635</R> und globale Zustände des Netzes nach der _Boltzmann-Verteilung_[^29] verhalten. Das Netz versucht lokale Minima zu überwinden (vgl. "Gradientenabstiegsverfahren" in **Kapitel 3.2.1 Backpropagation**), indem ihm erlaubt wird, zu größeren $E$ (**_3-2-2_**) zu springen, um so zu einem globalen Minimum zu konvergieren (<R>AHS85, S. 151</R> sowie <R>Koe90, S. 107</R>). Das Verfahren wird auch _simulated annealing_[^30] bezeichnet <R>Ert21, S. 297</R>.


[^18]: in asynchronen Modellen werden die Aktivierungen der Neuronen unabhängig voneinander und zu unterschiedlichen Zeitpunkten berechnet (vgl. <R>Roj02, S. 49</R> sowie ebenda S. 282)
[^19]: ehemalige Forschungsabteilung der Telefongesellschaft AT & T;  gehört seit 2016 zu Nokia (https://www.bell-labs.com/, abgerufen 03.09.2023)
[^20]: https://techmonitor.ai/technology/att_creates_parallel_neural_net_chip_to_solve_routing_problems
[^21]:  Ein rekurrentes neuronales Netz "speist seine Ausgaben wieder in seine eigenen Eingaben ein" <R>RN09, S. 847</R>: Im Gegensatz zu Feedforward-Netzen sind rekurrente Netze also _rückgekoppelt_
[^22]: Eine _Schlinge_ (engl. _loop_) in einem Graphen ist ein Kantenzug, der einen Knoten mit sich selbst verbindet <R>Die17 S. 30</R>. Ein Beispiel für ein Netz mit Schlingen ist das **MAXNET** <R>Lip87</R>, das zu der Gruppe der **competitive nets** gehört: Es kann als Subnetz zur Ermittlung der Zelle mit dem größten Aktivierungswert genutzt werden <R>Fau94, S. 158 ff.</R>
[^23]: Nach dem Training ist das Netz dazu in der Lage, für einen Stimulus ein Aktualisierungsmuster einzunehmen, dass diesem am ähnlichsten ist <R>RN09, S. 882</R>, was an die "Cell Assemblies" von Hebb erinnert (Kapitel 2.2.1). _Lansner_ verweist in <R>Lan09, S. 179</R> genau darauf, merkt aber gleichfalls an, dass das Modell aufgrund der Rekurrenz und Symmetrie nicht seinem biologischen Vorbild entspricht <R>Lan09, S.180</R>
[^24]: Rauschen bzw. Störungen bei Stimuli in Form von Bildern ($n * m$ Pixeln) können durch zufällig hinzugefügte oder entfernte Pixel entstehen, oder durch Rotation (axiale Verschiebung) der Daten vor dem Einspeisen in das Netz. Beispiele für verrauschte Daten in <R>Ert21, S 294 ff.</R>
[^25]: mit dem Faktor $1/2$, damit aufgrund der Symmetrie in dem Netz $w_{ij}x_ix_j$ und $w_{ji}x_jx_i$ nur einmal berechnet wird <R>Roj93, S.287</R>
[^26]: vgl. auch <R>AR98, S.417</R> sowie <R>Hop82, S.2556, "Studies of the collective behaviors of the model" f.</R>
[^27]: dem so genannten _Spinglass_ (auch: _spin glass_); vgl.<R>BY86, S. 900 mit Bezug auf Hopfield-Netze</R>
[^28]: eine Beschreibung des Verhalten findet sich 1983 bereits in <R>HS83</R>
[^29]: die _Boltzmann-Verteilung_ gibt die Wahrscheinlichkeit an, ein geg. physik. System in einem bestimmten Zustand anzutreffen (https://de.wikipedia.org/wiki/Boltzmann-Statistik, abgerufen  05.09.2023)
[^30]: "Gelingt es, die Temperatur nach dem richtigen Plan auf null zu verringern, wird sich das Netz mit großer Wahrscheinlichkeit in einem globalen Minimum stabilisieren." <R>Roj93, S. 322</R> Der Begriff _Annealing_ ist hier aus der Werkstoffkunde entlehnt: Eine entsprechende Wärmebehandlung von Materialien unterstützt die Erzeugung gewünschter Werkstoffeigenschaften wie Festigkeit, z.B.  bei der Verarbeitung von Glas <R>Jeb11, S. 3</R> oder Schweißverbindungen von Metallen <R>FJO+19</R>


### 3.2.3 Neocognitron

Unter dem Namen "Cognitron" 1975 beschreibt _Fukushima_ (1936 - ) in <R>Fuk75</R> ein mehrschichtiges Netz mit selbst-organisierenden Eigenschaften zur Mustererkennung, in dem Zellen selektiv auf häufig präsentierte Merkmale reagieren. 1983 veröffentlichen _Fukushima, Miyake und Ito_ eine Modifikation dieser Architektur in <R>FMI83</R>[^31] unter dem Namen **Neocognitron**[^32]; sein biologisches Vorbild ist das durch _Hubel und Wiesel_[^33] in <R>HU62</R> beschriebene hierarchische Modell des Wahrnehmungssystems <R>FMI83, S. 827</R>.<br /> In dem künstlichen neuronalen Netz haben Zellen in tiefer liegenden Schichten die Eigenschaft, selektiv komplexere Merkmale der Stimuli zu extrahieren, womit sie weniger anfällig auf Rauschen in den Eingabedaten sind. In <R>Fuk80</R> war der Training-Prozess des Modells gegeben durch wiederholte Einspeisung von Mustern ohne weitere Information[^34] <R>Fuk80, S.197</R>: Die Erweiterung des Modells beinhaltet nun die Verstärkung der modifizierten Synapsen durch überwachtes Lernen[^35], um bessere Resultate bei handgeschriebenen Zeichen zu erzielen <R>FMI83, S. 829</R>.<br />
_Anderson und Rosenfeld_ attestieren dem Netz von _Fukushima, Miyake und Ito_ Aspekte, die bei der Entwicklung neuronaler Netze eine wesentliche Rolle spielen werden <R>AR88, S. 524</R>:  Tatsächlich inspiriert das Neocognitron die Convolutional Neural Networks (CNN) <R>LBH15, S.439</R>, die LeCun in seiner Arbeit von 1989[^36] vorstellt.



[^31]: Mit Bezug auf <R>Fuk80</R> ("Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position")
[^32]: Video mit Demonstration des Netzes unter https://www.youtube.com/watch?v=Qil4kmvm2Sw, abgerufen 04.09.2023
[^33]: David H. Hubel (1926 - 2013) und Torsten N. Wiesel (1924 - ) erhalten 1981 den Nobelpreis für Physiologie oder Medizin  für ihre Entdeckungen bzgl. Informationsverarbeitung im Seewahrnehmungssystem (https://www.nobelprize.org/prizes/medicine/1981/summary/, abgerufen 05.09.2023). In der im folgenden zitierten Arbeit von 1962 zeigen sie, dass im Wahrnehmungssystem "einfache" und "komplexe" Neuronen existieren, die visuelle Informationen unterschiedlich verarbeiten <R>Wur09, S. 2819</R>
[^34]: "learning without a teacher", also unüberwachtes Lernen (unsupervised learning).
[^35]: "We use a learning-with-a-teacher process for the reinforcement of the modifiable synapses in the new large-scale
model, instead of the learning-without-a-teacher process applied to the previous model." <R>FMI83, S. 827</R>; _Anderson und Rosenfeld_ vermerken dies als "some handcrafted fine tuning" <R>AR88, S. 524 ff.</R>
[^36]: ein Jahr nach Erscheinen von <R>AR88</R>



#### Faltendes Netz
[Son22, S. 61]

## notizen

- RELU: in GBC18, S 192: nachweis Quelle, ausserdem Zitate: aus der Relu lssst sich ein universeller Funktionsappproximator bauen (siehe hierzu auch Son22 als universeller approximator - wenn Son22 S. 95 mit verweis dort auf [9] recht hat, muss eine hidden layer für ein Neuronales Netz zur Darstellung von XOR reichen)

Man darf nciht den Fehler machen, Deep Learning als Versuch zu sehen, das Gehirn zu simulieren [GBC18, S.18. Abs. 2]


> The result of this work, which also involved McCulloch and the Chilean
neuroanatomist Humberto Maturana and built on earlier insights of Hartline and Barlow, was the understanding that the
retina does not just relay information to the brain, but is already processing very subtle features of the visual input that
were, in some way, related to the ethology, the behavior, of the frog, with sets of these features sent in retinotopic layers
to the visual tectum of the midbrain. [Arb19, S. 6, Abs. 3]